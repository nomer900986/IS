{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "34fc3fb7",
   "metadata": {},
   "source": [
    "# Лабораторная работа № 5\n",
    "\n",
    "## Распознавание объектов на фотографиях\n",
    "\n",
    "Задачи:\n",
    "\n",
    "   1. Ознакомиться со сверточными нейронными сетями\n",
    "   2. Изучить построение модели в Keras в функциональном виде\n",
    "   3. Изучить работу слоя разреживания (Dropout)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e581aba",
   "metadata": {},
   "source": [
    "# Цель работы:\n",
    "Распознавание объектов на фотографиях (Object Recognition in Photographs)\n",
    "CIFAR-10 (классификация небольших изображений по десяти классам: самолет,\n",
    "автомобиль, птица, кошка, олень, собака, лягушка, лошадь, корабль и грузовик)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2ad17c35",
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.datasets import cifar10\n",
    "from keras.models import Model\n",
    "from keras.layers import Input, Convolution2D, MaxPooling2D, Dense, Dropout, Flatten\n",
    "from keras.utils import np_utils\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0acfd8f4-5f98-4f85-9862-41b4dddcfd11",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading data from https://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz\n",
      "170500096/170498071 [==============================] - 50s 0us/step\n",
      "170508288/170498071 [==============================] - 50s 0us/step\n",
      "313/313 [==============================] - 1s 4ms/step - loss: 457.1231 - accuracy: 0.2338\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[457.1231384277344, 0.2337999939918518]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "batch_size = 32 \n",
    "num_epochs = 200 \n",
    "kernel_size = 3 # использование ядра 3x3 \n",
    "pool_size = 2 #   использование объединения 2х2 \n",
    "conv_depth_1 = 32 #  32 ядра на слой преобразования\n",
    "conv_depth_2 = 64 # переход на 64 после первого уровня объединения\n",
    "drop_prob_1 = 0.25 #  вероятность 0,25\n",
    "drop_prob_2 = 0.5 #  в плотном слое вероятность 0,5\n",
    "hidden_size = 512 # в плотном слое 512 нейронов\n",
    "\n",
    "(X_train, y_train), (X_test, y_test) = cifar10.load_data() \n",
    "num_train, depth, height, width = X_train.shape \n",
    "num_test = X_test.shape[0] \n",
    "num_classes = np.unique(y_train).shape[0]\n",
    "X_train = X_train.astype('float32')\n",
    "X_test = X_test.astype('float32')\n",
    "X_train /= np.max(X_train)\n",
    "X_test /= np.max(X_train) \n",
    "\n",
    "Y_train = np_utils.to_categorical(y_train, num_classes) \n",
    "Y_test = np_utils.to_categorical(y_test, num_classes) \n",
    "\n",
    "\n",
    "inp = Input(shape=(depth, height, width)) # N.B. глубина занимает первое место в Керасе\n",
    "# Conv [32] -> Conv [32] -> Pool (with dropout on the pooling layer)\n",
    "conv_1 = Convolution2D(conv_depth_1, kernel_size, kernel_size,\n",
    "padding='same', activation='relu')(inp) #устарело\n",
    "conv_2 = Convolution2D(conv_depth_1, kernel_size, kernel_size,\n",
    "padding='same', activation='relu')(conv_1)\n",
    "pool_1 = MaxPooling2D(pool_size=(pool_size, pool_size))(conv_2)\n",
    "drop_1 = Dropout(drop_prob_1)(pool_1)  #Для предотвращения переобучения\n",
    "# Conv [64] -> Conv [64] -> Pool (with dropout on the pooling layer)\n",
    "conv_3 = Convolution2D(conv_depth_2, kernel_size, kernel_size,\n",
    "padding='same', activation='relu')(drop_1)\n",
    "conv_4 = Convolution2D(conv_depth_2, kernel_size, kernel_size,\n",
    "padding='same', activation='relu')(conv_3)\n",
    "pool_2 = MaxPooling2D(pool_size=(pool_size, pool_size),padding='same')(conv_4) # padding - сохранять\n",
    "#размер исходного изображения, рисунок дополняется нулями по краям. \n",
    "drop_2 = Dropout(drop_prob_1)(pool_2)\n",
    "#Теперь выровняйте до 1D, примените Плотный -> ReLU (с выпадением) -> softmax\n",
    "flat = Flatten()(drop_2)\n",
    "hidden = Dense(hidden_size, activation='relu')(flat)\n",
    "\n",
    "drop_3 = Dropout(drop_prob_2)(hidden)\n",
    "out = Dense(num_classes, activation='softmax')(drop_3)\n",
    "model = Model(inputs=inp, outputs=out) # Чтобы определить модель, просто укажите ее входные и выходные слои\n",
    "model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy']) \n",
    "model.fit(X_train, Y_train, batch_size=batch_size, epochs=num_epochs, verbose=0, validation_split=0.1) # \n",
    "model.evaluate(X_test, Y_test, verbose=1) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c8557f67-cb0d-4a0b-acc3-4fd5edf32e23",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/200\n",
      "1407/1407 [==============================] - 7s 4ms/step - loss: 1.8013 - accuracy: 0.3239 - val_loss: 1.6133 - val_accuracy: 0.3990\n",
      "Epoch 2/200\n",
      "1407/1407 [==============================] - 4s 3ms/step - loss: 1.5554 - accuracy: 0.4206 - val_loss: 1.4745 - val_accuracy: 0.4534\n",
      "Epoch 3/200\n",
      "1407/1407 [==============================] - 4s 3ms/step - loss: 1.4620 - accuracy: 0.4596 - val_loss: 1.4869 - val_accuracy: 0.4542\n",
      "Epoch 4/200\n",
      "1407/1407 [==============================] - 4s 3ms/step - loss: 1.4021 - accuracy: 0.4837 - val_loss: 1.3845 - val_accuracy: 0.4850\n",
      "Epoch 5/200\n",
      "1407/1407 [==============================] - 4s 3ms/step - loss: 1.3521 - accuracy: 0.5034 - val_loss: 1.3748 - val_accuracy: 0.4974\n",
      "Epoch 6/200\n",
      "1407/1407 [==============================] - 4s 3ms/step - loss: 1.3089 - accuracy: 0.5226 - val_loss: 1.3415 - val_accuracy: 0.5090\n",
      "Epoch 7/200\n",
      "1407/1407 [==============================] - 4s 3ms/step - loss: 1.2768 - accuracy: 0.5356 - val_loss: 1.3000 - val_accuracy: 0.5240\n",
      "Epoch 8/200\n",
      "1407/1407 [==============================] - 5s 3ms/step - loss: 1.2456 - accuracy: 0.5458 - val_loss: 1.3415 - val_accuracy: 0.5162\n",
      "Epoch 9/200\n",
      "1407/1407 [==============================] - 5s 4ms/step - loss: 1.2192 - accuracy: 0.5585 - val_loss: 1.2737 - val_accuracy: 0.5400\n",
      "Epoch 10/200\n",
      "1407/1407 [==============================] - 4s 3ms/step - loss: 1.1957 - accuracy: 0.5643 - val_loss: 1.2656 - val_accuracy: 0.5448\n",
      "Epoch 11/200\n",
      "1407/1407 [==============================] - 5s 3ms/step - loss: 1.1765 - accuracy: 0.5722 - val_loss: 1.2848 - val_accuracy: 0.5440\n",
      "Epoch 12/200\n",
      "1407/1407 [==============================] - 5s 4ms/step - loss: 1.1571 - accuracy: 0.5812 - val_loss: 1.2657 - val_accuracy: 0.5454\n",
      "Epoch 13/200\n",
      "1407/1407 [==============================] - 5s 4ms/step - loss: 1.1385 - accuracy: 0.5887 - val_loss: 1.2320 - val_accuracy: 0.5596\n",
      "Epoch 14/200\n",
      "1407/1407 [==============================] - 6s 5ms/step - loss: 1.1220 - accuracy: 0.5942 - val_loss: 1.2590 - val_accuracy: 0.5440\n",
      "Epoch 15/200\n",
      "1407/1407 [==============================] - 4s 3ms/step - loss: 1.1100 - accuracy: 0.5989 - val_loss: 1.2696 - val_accuracy: 0.5480\n",
      "Epoch 16/200\n",
      "1407/1407 [==============================] - 6s 4ms/step - loss: 1.0912 - accuracy: 0.6059 - val_loss: 1.2497 - val_accuracy: 0.5570\n",
      "Epoch 17/200\n",
      "1407/1407 [==============================] - 11s 8ms/step - loss: 1.0810 - accuracy: 0.6076 - val_loss: 1.2270 - val_accuracy: 0.5588\n",
      "Epoch 18/200\n",
      "1407/1407 [==============================] - 4s 3ms/step - loss: 1.0652 - accuracy: 0.6139 - val_loss: 1.2281 - val_accuracy: 0.5610\n",
      "Epoch 19/200\n",
      "1407/1407 [==============================] - 4s 3ms/step - loss: 1.0484 - accuracy: 0.6192 - val_loss: 1.2454 - val_accuracy: 0.5588\n",
      "Epoch 20/200\n",
      "1407/1407 [==============================] - 4s 3ms/step - loss: 1.0384 - accuracy: 0.6231 - val_loss: 1.2307 - val_accuracy: 0.5638\n",
      "Epoch 21/200\n",
      "1407/1407 [==============================] - 4s 3ms/step - loss: 1.0285 - accuracy: 0.6253 - val_loss: 1.2387 - val_accuracy: 0.5702\n",
      "Epoch 22/200\n",
      "1407/1407 [==============================] - 4s 3ms/step - loss: 1.0191 - accuracy: 0.6300 - val_loss: 1.2435 - val_accuracy: 0.5648\n",
      "Epoch 23/200\n",
      "1407/1407 [==============================] - 4s 3ms/step - loss: 1.0022 - accuracy: 0.6357 - val_loss: 1.2418 - val_accuracy: 0.5630\n",
      "Epoch 24/200\n",
      "1407/1407 [==============================] - 4s 3ms/step - loss: 0.9886 - accuracy: 0.6410 - val_loss: 1.2722 - val_accuracy: 0.5620\n",
      "Epoch 25/200\n",
      "1407/1407 [==============================] - 4s 3ms/step - loss: 0.9772 - accuracy: 0.6437 - val_loss: 1.2926 - val_accuracy: 0.5598\n",
      "Epoch 26/200\n",
      "1407/1407 [==============================] - 4s 3ms/step - loss: 0.9661 - accuracy: 0.6504 - val_loss: 1.2762 - val_accuracy: 0.5518\n",
      "Epoch 27/200\n",
      "1407/1407 [==============================] - 4s 3ms/step - loss: 0.9546 - accuracy: 0.6514 - val_loss: 1.2467 - val_accuracy: 0.5696\n",
      "Epoch 28/200\n",
      "1407/1407 [==============================] - 4s 3ms/step - loss: 0.9460 - accuracy: 0.6573 - val_loss: 1.2921 - val_accuracy: 0.5654\n",
      "Epoch 29/200\n",
      "1407/1407 [==============================] - 4s 3ms/step - loss: 0.9297 - accuracy: 0.6592 - val_loss: 1.3410 - val_accuracy: 0.5506\n",
      "Epoch 30/200\n",
      "1407/1407 [==============================] - 4s 3ms/step - loss: 0.9221 - accuracy: 0.6612 - val_loss: 1.3056 - val_accuracy: 0.5612\n",
      "Epoch 31/200\n",
      "1407/1407 [==============================] - 4s 3ms/step - loss: 0.9124 - accuracy: 0.6668 - val_loss: 1.2910 - val_accuracy: 0.5658\n",
      "Epoch 32/200\n",
      "1407/1407 [==============================] - 4s 3ms/step - loss: 0.9002 - accuracy: 0.6708 - val_loss: 1.3988 - val_accuracy: 0.5574\n",
      "Epoch 33/200\n",
      "1407/1407 [==============================] - 4s 3ms/step - loss: 0.8874 - accuracy: 0.6762 - val_loss: 1.3308 - val_accuracy: 0.5664\n",
      "Epoch 34/200\n",
      "1407/1407 [==============================] - 4s 3ms/step - loss: 0.8803 - accuracy: 0.6776 - val_loss: 1.3456 - val_accuracy: 0.5596\n",
      "Epoch 35/200\n",
      "1407/1407 [==============================] - 4s 3ms/step - loss: 0.8690 - accuracy: 0.6801 - val_loss: 1.3398 - val_accuracy: 0.5708\n",
      "Epoch 36/200\n",
      "1407/1407 [==============================] - 4s 3ms/step - loss: 0.8585 - accuracy: 0.6849 - val_loss: 1.4033 - val_accuracy: 0.5492\n",
      "Epoch 37/200\n",
      "1407/1407 [==============================] - 4s 3ms/step - loss: 0.8483 - accuracy: 0.6875 - val_loss: 1.3990 - val_accuracy: 0.5566\n",
      "Epoch 38/200\n",
      "1407/1407 [==============================] - 4s 3ms/step - loss: 0.8359 - accuracy: 0.6930 - val_loss: 1.3664 - val_accuracy: 0.5564\n",
      "Epoch 39/200\n",
      "1407/1407 [==============================] - 4s 3ms/step - loss: 0.8260 - accuracy: 0.6950 - val_loss: 1.3972 - val_accuracy: 0.5580\n",
      "Epoch 40/200\n",
      "1407/1407 [==============================] - 4s 3ms/step - loss: 0.8158 - accuracy: 0.6996 - val_loss: 1.4186 - val_accuracy: 0.5546\n",
      "Epoch 41/200\n",
      "1407/1407 [==============================] - 4s 3ms/step - loss: 0.8090 - accuracy: 0.7022 - val_loss: 1.4103 - val_accuracy: 0.5528\n",
      "Epoch 42/200\n",
      "1407/1407 [==============================] - 4s 3ms/step - loss: 0.7971 - accuracy: 0.7053 - val_loss: 1.4656 - val_accuracy: 0.5512\n",
      "Epoch 43/200\n",
      "1407/1407 [==============================] - 4s 3ms/step - loss: 0.7902 - accuracy: 0.7088 - val_loss: 1.4653 - val_accuracy: 0.5498\n",
      "Epoch 44/200\n",
      "1407/1407 [==============================] - 4s 3ms/step - loss: 0.7768 - accuracy: 0.7130 - val_loss: 1.5187 - val_accuracy: 0.5508\n",
      "Epoch 45/200\n",
      "1407/1407 [==============================] - 4s 3ms/step - loss: 0.7673 - accuracy: 0.7161 - val_loss: 1.5476 - val_accuracy: 0.5438\n",
      "Epoch 46/200\n",
      "1407/1407 [==============================] - 4s 3ms/step - loss: 0.7569 - accuracy: 0.7187 - val_loss: 1.4942 - val_accuracy: 0.5456\n",
      "Epoch 47/200\n",
      "1407/1407 [==============================] - 4s 3ms/step - loss: 0.7510 - accuracy: 0.7223 - val_loss: 1.6025 - val_accuracy: 0.5444\n",
      "Epoch 48/200\n",
      "1407/1407 [==============================] - 4s 3ms/step - loss: 0.7470 - accuracy: 0.7238 - val_loss: 1.5830 - val_accuracy: 0.5392\n",
      "Epoch 49/200\n",
      "1407/1407 [==============================] - 4s 3ms/step - loss: 0.7327 - accuracy: 0.7285 - val_loss: 1.5931 - val_accuracy: 0.5388\n",
      "Epoch 50/200\n",
      "1407/1407 [==============================] - 5s 3ms/step - loss: 0.7192 - accuracy: 0.7356 - val_loss: 1.6053 - val_accuracy: 0.5412\n",
      "Epoch 51/200\n",
      "1407/1407 [==============================] - 5s 3ms/step - loss: 0.7188 - accuracy: 0.7324 - val_loss: 1.6030 - val_accuracy: 0.5416\n",
      "Epoch 52/200\n",
      "1407/1407 [==============================] - 4s 3ms/step - loss: 0.7055 - accuracy: 0.7366 - val_loss: 1.6711 - val_accuracy: 0.5348\n",
      "Epoch 53/200\n",
      "1407/1407 [==============================] - 4s 3ms/step - loss: 0.7018 - accuracy: 0.7387 - val_loss: 1.6582 - val_accuracy: 0.5364\n",
      "Epoch 54/200\n",
      "1407/1407 [==============================] - 4s 3ms/step - loss: 0.6910 - accuracy: 0.7420 - val_loss: 1.6855 - val_accuracy: 0.5400\n",
      "Epoch 55/200\n",
      "1407/1407 [==============================] - 4s 3ms/step - loss: 0.6804 - accuracy: 0.7468 - val_loss: 1.7093 - val_accuracy: 0.5378\n",
      "Epoch 56/200\n",
      "1407/1407 [==============================] - 4s 3ms/step - loss: 0.6779 - accuracy: 0.7467 - val_loss: 1.7712 - val_accuracy: 0.5328\n",
      "Epoch 57/200\n",
      "1407/1407 [==============================] - 4s 3ms/step - loss: 0.6755 - accuracy: 0.7461 - val_loss: 1.7340 - val_accuracy: 0.5394\n",
      "Epoch 58/200\n",
      "1407/1407 [==============================] - 4s 3ms/step - loss: 0.6661 - accuracy: 0.7525 - val_loss: 1.8664 - val_accuracy: 0.5402\n",
      "Epoch 59/200\n",
      "1407/1407 [==============================] - 4s 3ms/step - loss: 0.6576 - accuracy: 0.7545 - val_loss: 1.8208 - val_accuracy: 0.5342\n",
      "Epoch 60/200\n",
      "1407/1407 [==============================] - 4s 3ms/step - loss: 0.6509 - accuracy: 0.7572 - val_loss: 1.7556 - val_accuracy: 0.5358\n",
      "Epoch 61/200\n",
      "1407/1407 [==============================] - 4s 3ms/step - loss: 0.6439 - accuracy: 0.7599 - val_loss: 1.7987 - val_accuracy: 0.5390\n",
      "Epoch 62/200\n",
      "1407/1407 [==============================] - 4s 3ms/step - loss: 0.6413 - accuracy: 0.7616 - val_loss: 1.8517 - val_accuracy: 0.5240\n",
      "Epoch 63/200\n",
      "1407/1407 [==============================] - 4s 3ms/step - loss: 0.6298 - accuracy: 0.7649 - val_loss: 1.8183 - val_accuracy: 0.5414\n",
      "Epoch 64/200\n",
      "1407/1407 [==============================] - 4s 3ms/step - loss: 0.6273 - accuracy: 0.7662 - val_loss: 1.8803 - val_accuracy: 0.5304\n",
      "Epoch 65/200\n",
      "1407/1407 [==============================] - 4s 3ms/step - loss: 0.6140 - accuracy: 0.7688 - val_loss: 1.9331 - val_accuracy: 0.5360\n",
      "Epoch 66/200\n",
      "1407/1407 [==============================] - 4s 3ms/step - loss: 0.6195 - accuracy: 0.7685 - val_loss: 1.9505 - val_accuracy: 0.5318\n",
      "Epoch 67/200\n",
      "1407/1407 [==============================] - 4s 3ms/step - loss: 0.6014 - accuracy: 0.7744 - val_loss: 1.9155 - val_accuracy: 0.5330\n",
      "Epoch 68/200\n",
      "1407/1407 [==============================] - 4s 3ms/step - loss: 0.6059 - accuracy: 0.7739 - val_loss: 1.9436 - val_accuracy: 0.5358\n",
      "Epoch 69/200\n",
      "1407/1407 [==============================] - 4s 3ms/step - loss: 0.5929 - accuracy: 0.7791 - val_loss: 1.9577 - val_accuracy: 0.5332\n",
      "Epoch 70/200\n",
      "1407/1407 [==============================] - 4s 3ms/step - loss: 0.5946 - accuracy: 0.7784 - val_loss: 2.0231 - val_accuracy: 0.5344\n",
      "Epoch 71/200\n",
      "1407/1407 [==============================] - 4s 3ms/step - loss: 0.5838 - accuracy: 0.7788 - val_loss: 2.0430 - val_accuracy: 0.5310\n",
      "Epoch 72/200\n",
      "1407/1407 [==============================] - 4s 3ms/step - loss: 0.5834 - accuracy: 0.7827 - val_loss: 2.0366 - val_accuracy: 0.5252\n",
      "Epoch 73/200\n",
      "1407/1407 [==============================] - 4s 3ms/step - loss: 0.5729 - accuracy: 0.7865 - val_loss: 2.0948 - val_accuracy: 0.5294\n",
      "Epoch 74/200\n",
      "1407/1407 [==============================] - 5s 3ms/step - loss: 0.5710 - accuracy: 0.7876 - val_loss: 2.1763 - val_accuracy: 0.5292\n",
      "Epoch 75/200\n",
      "1407/1407 [==============================] - 5s 3ms/step - loss: 0.5702 - accuracy: 0.7866 - val_loss: 2.1293 - val_accuracy: 0.5280\n",
      "Epoch 76/200\n",
      "1407/1407 [==============================] - 4s 3ms/step - loss: 0.5574 - accuracy: 0.7927 - val_loss: 2.1144 - val_accuracy: 0.5196\n",
      "Epoch 77/200\n",
      "1407/1407 [==============================] - 4s 3ms/step - loss: 0.5615 - accuracy: 0.7924 - val_loss: 2.1783 - val_accuracy: 0.5284\n",
      "Epoch 78/200\n",
      "1407/1407 [==============================] - 4s 3ms/step - loss: 0.5499 - accuracy: 0.7942 - val_loss: 2.2779 - val_accuracy: 0.5306\n",
      "Epoch 79/200\n",
      "1407/1407 [==============================] - 4s 3ms/step - loss: 0.5558 - accuracy: 0.7930 - val_loss: 2.1595 - val_accuracy: 0.5242\n",
      "Epoch 80/200\n",
      "1407/1407 [==============================] - 4s 3ms/step - loss: 0.5510 - accuracy: 0.7942 - val_loss: 2.2352 - val_accuracy: 0.5230\n",
      "Epoch 81/200\n",
      "1407/1407 [==============================] - 4s 3ms/step - loss: 0.5431 - accuracy: 0.7965 - val_loss: 2.1913 - val_accuracy: 0.5264\n",
      "Epoch 82/200\n",
      "1407/1407 [==============================] - 4s 3ms/step - loss: 0.5299 - accuracy: 0.8039 - val_loss: 2.2863 - val_accuracy: 0.5240\n",
      "Epoch 83/200\n",
      "1407/1407 [==============================] - 4s 3ms/step - loss: 0.5385 - accuracy: 0.7990 - val_loss: 2.2358 - val_accuracy: 0.5272\n",
      "Epoch 84/200\n",
      "1407/1407 [==============================] - 4s 3ms/step - loss: 0.5290 - accuracy: 0.8026 - val_loss: 2.4003 - val_accuracy: 0.5210\n",
      "Epoch 85/200\n",
      "1407/1407 [==============================] - 4s 3ms/step - loss: 0.5217 - accuracy: 0.8069 - val_loss: 2.3956 - val_accuracy: 0.5214\n",
      "Epoch 86/200\n",
      "1407/1407 [==============================] - 4s 3ms/step - loss: 0.5286 - accuracy: 0.8030 - val_loss: 2.3735 - val_accuracy: 0.5232\n",
      "Epoch 87/200\n",
      "1407/1407 [==============================] - 5s 3ms/step - loss: 0.5150 - accuracy: 0.8075 - val_loss: 2.3622 - val_accuracy: 0.5250\n",
      "Epoch 88/200\n",
      "1407/1407 [==============================] - 5s 3ms/step - loss: 0.5188 - accuracy: 0.8072 - val_loss: 2.4090 - val_accuracy: 0.5264\n",
      "Epoch 89/200\n",
      "1407/1407 [==============================] - 5s 3ms/step - loss: 0.5194 - accuracy: 0.8078 - val_loss: 2.4033 - val_accuracy: 0.5230\n",
      "Epoch 90/200\n",
      "1407/1407 [==============================] - 4s 3ms/step - loss: 0.5110 - accuracy: 0.8105 - val_loss: 2.3633 - val_accuracy: 0.5186\n",
      "Epoch 91/200\n",
      "1407/1407 [==============================] - 5s 3ms/step - loss: 0.4950 - accuracy: 0.8151 - val_loss: 2.4735 - val_accuracy: 0.5242\n",
      "Epoch 92/200\n",
      "1407/1407 [==============================] - 4s 3ms/step - loss: 0.5011 - accuracy: 0.8138 - val_loss: 2.5606 - val_accuracy: 0.5164\n",
      "Epoch 93/200\n",
      "1407/1407 [==============================] - 4s 3ms/step - loss: 0.4987 - accuracy: 0.8151 - val_loss: 2.5286 - val_accuracy: 0.5158\n",
      "Epoch 94/200\n",
      "1407/1407 [==============================] - 4s 3ms/step - loss: 0.4985 - accuracy: 0.8153 - val_loss: 2.4735 - val_accuracy: 0.5162\n",
      "Epoch 95/200\n",
      "1407/1407 [==============================] - 5s 3ms/step - loss: 0.4989 - accuracy: 0.8138 - val_loss: 2.5355 - val_accuracy: 0.5078\n",
      "Epoch 96/200\n",
      "1407/1407 [==============================] - 5s 4ms/step - loss: 0.4935 - accuracy: 0.8156 - val_loss: 2.5123 - val_accuracy: 0.5238\n",
      "Epoch 97/200\n",
      "1407/1407 [==============================] - 5s 4ms/step - loss: 0.4947 - accuracy: 0.8175 - val_loss: 2.5620 - val_accuracy: 0.5194\n",
      "Epoch 98/200\n",
      "1407/1407 [==============================] - 6s 4ms/step - loss: 0.4884 - accuracy: 0.8180 - val_loss: 2.5236 - val_accuracy: 0.5102\n",
      "Epoch 99/200\n",
      "1407/1407 [==============================] - 6s 4ms/step - loss: 0.4931 - accuracy: 0.8170 - val_loss: 2.6973 - val_accuracy: 0.5158\n",
      "Epoch 100/200\n",
      "1407/1407 [==============================] - 5s 4ms/step - loss: 0.4807 - accuracy: 0.8217 - val_loss: 2.7374 - val_accuracy: 0.5202\n",
      "Epoch 101/200\n",
      "1407/1407 [==============================] - 5s 4ms/step - loss: 0.4733 - accuracy: 0.8239 - val_loss: 2.6509 - val_accuracy: 0.5172\n",
      "Epoch 102/200\n",
      "1407/1407 [==============================] - 5s 4ms/step - loss: 0.4793 - accuracy: 0.8208 - val_loss: 2.6227 - val_accuracy: 0.5162\n",
      "Epoch 103/200\n",
      "1407/1407 [==============================] - 5s 3ms/step - loss: 0.4733 - accuracy: 0.8245 - val_loss: 2.6375 - val_accuracy: 0.5180\n",
      "Epoch 104/200\n",
      "1407/1407 [==============================] - 6s 4ms/step - loss: 0.4674 - accuracy: 0.8265 - val_loss: 2.7406 - val_accuracy: 0.5132\n",
      "Epoch 105/200\n",
      "1407/1407 [==============================] - 5s 4ms/step - loss: 0.4703 - accuracy: 0.8252 - val_loss: 2.6559 - val_accuracy: 0.5142\n",
      "Epoch 106/200\n",
      "1407/1407 [==============================] - 5s 4ms/step - loss: 0.4602 - accuracy: 0.8300 - val_loss: 2.8328 - val_accuracy: 0.5152\n",
      "Epoch 107/200\n",
      "1407/1407 [==============================] - 5s 4ms/step - loss: 0.4765 - accuracy: 0.8230 - val_loss: 2.7310 - val_accuracy: 0.5128\n",
      "Epoch 108/200\n",
      "1407/1407 [==============================] - 5s 4ms/step - loss: 0.4500 - accuracy: 0.8305 - val_loss: 2.7164 - val_accuracy: 0.5164\n",
      "Epoch 109/200\n",
      "1407/1407 [==============================] - 5s 4ms/step - loss: 0.4622 - accuracy: 0.8303 - val_loss: 2.7323 - val_accuracy: 0.5232\n",
      "Epoch 110/200\n",
      "1407/1407 [==============================] - 5s 4ms/step - loss: 0.4622 - accuracy: 0.8306 - val_loss: 2.8548 - val_accuracy: 0.5122\n",
      "Epoch 111/200\n",
      "1407/1407 [==============================] - 6s 4ms/step - loss: 0.4541 - accuracy: 0.8320 - val_loss: 2.8513 - val_accuracy: 0.5114\n",
      "Epoch 112/200\n",
      "1407/1407 [==============================] - 5s 4ms/step - loss: 0.4474 - accuracy: 0.8344 - val_loss: 2.8334 - val_accuracy: 0.5132\n",
      "Epoch 113/200\n",
      "1407/1407 [==============================] - 5s 4ms/step - loss: 0.4516 - accuracy: 0.8322 - val_loss: 2.8008 - val_accuracy: 0.5148\n",
      "Epoch 114/200\n",
      "1407/1407 [==============================] - 6s 4ms/step - loss: 0.4348 - accuracy: 0.8381 - val_loss: 2.8688 - val_accuracy: 0.5090\n",
      "Epoch 115/200\n",
      "1407/1407 [==============================] - 6s 4ms/step - loss: 0.4522 - accuracy: 0.8336 - val_loss: 2.8716 - val_accuracy: 0.5186\n",
      "Epoch 116/200\n",
      "1407/1407 [==============================] - 5s 4ms/step - loss: 0.4476 - accuracy: 0.8352 - val_loss: 2.8315 - val_accuracy: 0.5172\n",
      "Epoch 117/200\n",
      "1407/1407 [==============================] - 5s 4ms/step - loss: 0.4469 - accuracy: 0.8342 - val_loss: 2.9122 - val_accuracy: 0.5250\n",
      "Epoch 118/200\n",
      "1407/1407 [==============================] - 6s 4ms/step - loss: 0.4370 - accuracy: 0.8385 - val_loss: 2.9016 - val_accuracy: 0.5162\n",
      "Epoch 119/200\n",
      "1407/1407 [==============================] - 5s 4ms/step - loss: 0.4372 - accuracy: 0.8370 - val_loss: 2.8763 - val_accuracy: 0.5206\n",
      "Epoch 120/200\n",
      "1407/1407 [==============================] - 6s 4ms/step - loss: 0.4371 - accuracy: 0.8396 - val_loss: 2.9929 - val_accuracy: 0.5192\n",
      "Epoch 121/200\n",
      "1407/1407 [==============================] - 5s 4ms/step - loss: 0.4344 - accuracy: 0.8405 - val_loss: 3.0195 - val_accuracy: 0.5124\n",
      "Epoch 122/200\n",
      "1407/1407 [==============================] - 5s 4ms/step - loss: 0.4417 - accuracy: 0.8366 - val_loss: 2.9228 - val_accuracy: 0.5064\n",
      "Epoch 123/200\n",
      "1407/1407 [==============================] - 5s 4ms/step - loss: 0.4252 - accuracy: 0.8413 - val_loss: 2.9934 - val_accuracy: 0.5190\n",
      "Epoch 124/200\n",
      "1407/1407 [==============================] - 6s 4ms/step - loss: 0.4311 - accuracy: 0.8404 - val_loss: 3.1875 - val_accuracy: 0.5044\n",
      "Epoch 125/200\n",
      "1407/1407 [==============================] - 6s 5ms/step - loss: 0.4269 - accuracy: 0.8422 - val_loss: 3.0569 - val_accuracy: 0.5188\n",
      "Epoch 126/200\n",
      "1407/1407 [==============================] - 8s 6ms/step - loss: 0.4279 - accuracy: 0.8426 - val_loss: 3.0594 - val_accuracy: 0.5180\n",
      "Epoch 127/200\n",
      "1407/1407 [==============================] - 7s 5ms/step - loss: 0.4284 - accuracy: 0.8417 - val_loss: 3.0811 - val_accuracy: 0.5098\n",
      "Epoch 128/200\n",
      "1407/1407 [==============================] - 7s 5ms/step - loss: 0.4233 - accuracy: 0.8450 - val_loss: 3.0164 - val_accuracy: 0.5200\n",
      "Epoch 129/200\n",
      "1407/1407 [==============================] - 7s 5ms/step - loss: 0.4206 - accuracy: 0.8445 - val_loss: 3.0495 - val_accuracy: 0.5196\n",
      "Epoch 130/200\n",
      "1407/1407 [==============================] - 6s 5ms/step - loss: 0.4267 - accuracy: 0.8430 - val_loss: 3.1734 - val_accuracy: 0.5148\n",
      "Epoch 131/200\n",
      "1407/1407 [==============================] - 7s 5ms/step - loss: 0.4263 - accuracy: 0.8448 - val_loss: 3.1527 - val_accuracy: 0.5104\n",
      "Epoch 132/200\n",
      "1407/1407 [==============================] - 7s 5ms/step - loss: 0.4166 - accuracy: 0.8438 - val_loss: 3.1326 - val_accuracy: 0.5070\n",
      "Epoch 133/200\n",
      "1407/1407 [==============================] - 6s 5ms/step - loss: 0.4123 - accuracy: 0.8460 - val_loss: 3.2143 - val_accuracy: 0.5146\n",
      "Epoch 134/200\n",
      "1407/1407 [==============================] - 7s 5ms/step - loss: 0.4209 - accuracy: 0.8452 - val_loss: 3.1294 - val_accuracy: 0.5170\n",
      "Epoch 135/200\n",
      "1407/1407 [==============================] - 7s 5ms/step - loss: 0.4202 - accuracy: 0.8453 - val_loss: 3.1064 - val_accuracy: 0.5004\n",
      "Epoch 136/200\n",
      "1407/1407 [==============================] - 6s 5ms/step - loss: 0.4177 - accuracy: 0.8460 - val_loss: 3.2293 - val_accuracy: 0.5166\n",
      "Epoch 137/200\n",
      "1407/1407 [==============================] - 6s 5ms/step - loss: 0.4101 - accuracy: 0.8475 - val_loss: 3.2578 - val_accuracy: 0.5086\n",
      "Epoch 138/200\n",
      "1407/1407 [==============================] - 6s 4ms/step - loss: 0.4138 - accuracy: 0.8458 - val_loss: 3.1550 - val_accuracy: 0.5210\n",
      "Epoch 139/200\n",
      "1407/1407 [==============================] - 6s 5ms/step - loss: 0.4003 - accuracy: 0.8531 - val_loss: 3.2717 - val_accuracy: 0.5120\n",
      "Epoch 140/200\n",
      "1407/1407 [==============================] - 6s 5ms/step - loss: 0.4126 - accuracy: 0.8504 - val_loss: 3.2569 - val_accuracy: 0.5110\n",
      "Epoch 141/200\n",
      "1407/1407 [==============================] - 7s 5ms/step - loss: 0.4113 - accuracy: 0.8485 - val_loss: 3.1738 - val_accuracy: 0.5092\n",
      "Epoch 142/200\n",
      "1407/1407 [==============================] - 7s 5ms/step - loss: 0.4027 - accuracy: 0.8532 - val_loss: 3.3665 - val_accuracy: 0.5106\n",
      "Epoch 143/200\n",
      "1407/1407 [==============================] - 6s 4ms/step - loss: 0.4159 - accuracy: 0.8497 - val_loss: 3.2444 - val_accuracy: 0.5060\n",
      "Epoch 144/200\n",
      "1407/1407 [==============================] - 6s 4ms/step - loss: 0.4084 - accuracy: 0.8495 - val_loss: 3.3051 - val_accuracy: 0.5054\n",
      "Epoch 145/200\n",
      "1407/1407 [==============================] - 7s 5ms/step - loss: 0.3922 - accuracy: 0.8552 - val_loss: 3.4060 - val_accuracy: 0.5086\n",
      "Epoch 146/200\n",
      "1407/1407 [==============================] - 7s 5ms/step - loss: 0.4070 - accuracy: 0.8528 - val_loss: 3.3166 - val_accuracy: 0.5162\n",
      "Epoch 147/200\n",
      "1407/1407 [==============================] - 6s 4ms/step - loss: 0.3970 - accuracy: 0.8528 - val_loss: 3.3348 - val_accuracy: 0.5160\n",
      "Epoch 148/200\n",
      "1407/1407 [==============================] - 8s 6ms/step - loss: 0.3995 - accuracy: 0.8544 - val_loss: 3.3736 - val_accuracy: 0.5188\n",
      "Epoch 149/200\n",
      "1407/1407 [==============================] - 11s 8ms/step - loss: 0.3915 - accuracy: 0.8574 - val_loss: 3.4337 - val_accuracy: 0.5134\n",
      "Epoch 150/200\n",
      "1407/1407 [==============================] - 10s 7ms/step - loss: 0.3877 - accuracy: 0.8575 - val_loss: 3.3479 - val_accuracy: 0.5142\n",
      "Epoch 151/200\n",
      "1407/1407 [==============================] - 8s 6ms/step - loss: 0.3968 - accuracy: 0.8555 - val_loss: 3.5237 - val_accuracy: 0.5126\n",
      "Epoch 152/200\n",
      "1407/1407 [==============================] - 7s 5ms/step - loss: 0.3895 - accuracy: 0.8570 - val_loss: 3.4800 - val_accuracy: 0.5170\n",
      "Epoch 153/200\n",
      "1407/1407 [==============================] - 9s 6ms/step - loss: 0.3923 - accuracy: 0.8553 - val_loss: 3.4909 - val_accuracy: 0.5214\n",
      "Epoch 154/200\n",
      "1407/1407 [==============================] - 8s 5ms/step - loss: 0.4043 - accuracy: 0.8526 - val_loss: 3.4975 - val_accuracy: 0.5124\n",
      "Epoch 155/200\n",
      "1407/1407 [==============================] - 6s 4ms/step - loss: 0.3932 - accuracy: 0.8568 - val_loss: 3.4303 - val_accuracy: 0.5128\n",
      "Epoch 156/200\n",
      "1407/1407 [==============================] - 8s 6ms/step - loss: 0.4052 - accuracy: 0.8515 - val_loss: 3.4028 - val_accuracy: 0.5076\n",
      "Epoch 157/200\n",
      "1407/1407 [==============================] - 7s 5ms/step - loss: 0.3851 - accuracy: 0.8593 - val_loss: 3.4908 - val_accuracy: 0.5110\n",
      "Epoch 158/200\n",
      "1407/1407 [==============================] - 8s 6ms/step - loss: 0.3884 - accuracy: 0.8590 - val_loss: 3.4336 - val_accuracy: 0.5048\n",
      "Epoch 159/200\n",
      "1407/1407 [==============================] - 8s 6ms/step - loss: 0.3810 - accuracy: 0.8592 - val_loss: 3.6395 - val_accuracy: 0.5126\n",
      "Epoch 160/200\n",
      "1407/1407 [==============================] - 8s 6ms/step - loss: 0.3966 - accuracy: 0.8571 - val_loss: 3.6870 - val_accuracy: 0.5084\n",
      "Epoch 161/200\n",
      "1407/1407 [==============================] - 7s 5ms/step - loss: 0.3858 - accuracy: 0.8592 - val_loss: 3.6282 - val_accuracy: 0.5172\n",
      "Epoch 162/200\n",
      "1407/1407 [==============================] - 7s 5ms/step - loss: 0.3805 - accuracy: 0.8617 - val_loss: 3.7547 - val_accuracy: 0.5206\n",
      "Epoch 163/200\n",
      "1407/1407 [==============================] - 8s 6ms/step - loss: 0.3960 - accuracy: 0.8585 - val_loss: 3.5729 - val_accuracy: 0.5098\n",
      "Epoch 164/200\n",
      "1407/1407 [==============================] - 7s 5ms/step - loss: 0.3816 - accuracy: 0.8618 - val_loss: 3.7296 - val_accuracy: 0.5170\n",
      "Epoch 165/200\n",
      "1407/1407 [==============================] - 7s 5ms/step - loss: 0.3764 - accuracy: 0.8639 - val_loss: 3.5611 - val_accuracy: 0.5112\n",
      "Epoch 166/200\n",
      "1407/1407 [==============================] - 5s 4ms/step - loss: 0.3866 - accuracy: 0.8594 - val_loss: 3.5728 - val_accuracy: 0.5108\n",
      "Epoch 167/200\n",
      "1407/1407 [==============================] - 5s 4ms/step - loss: 0.3750 - accuracy: 0.8642 - val_loss: 3.5762 - val_accuracy: 0.5130\n",
      "Epoch 168/200\n",
      "1407/1407 [==============================] - 5s 4ms/step - loss: 0.3606 - accuracy: 0.8677 - val_loss: 3.7369 - val_accuracy: 0.5088\n",
      "Epoch 169/200\n",
      "1407/1407 [==============================] - 5s 4ms/step - loss: 0.3850 - accuracy: 0.8615 - val_loss: 3.6911 - val_accuracy: 0.5108\n",
      "Epoch 170/200\n",
      "1407/1407 [==============================] - 6s 4ms/step - loss: 0.3863 - accuracy: 0.8617 - val_loss: 3.7070 - val_accuracy: 0.5132\n",
      "Epoch 171/200\n",
      "1407/1407 [==============================] - 7s 5ms/step - loss: 0.3646 - accuracy: 0.8669 - val_loss: 3.6046 - val_accuracy: 0.4990\n",
      "Epoch 172/200\n",
      "1407/1407 [==============================] - 7s 5ms/step - loss: 0.3830 - accuracy: 0.8610 - val_loss: 3.7374 - val_accuracy: 0.5126\n",
      "Epoch 173/200\n",
      "1407/1407 [==============================] - 7s 5ms/step - loss: 0.3828 - accuracy: 0.8616 - val_loss: 3.7191 - val_accuracy: 0.5192\n",
      "Epoch 174/200\n",
      "1407/1407 [==============================] - 7s 5ms/step - loss: 0.3664 - accuracy: 0.8661 - val_loss: 3.7878 - val_accuracy: 0.5116\n",
      "Epoch 175/200\n",
      "1407/1407 [==============================] - 7s 5ms/step - loss: 0.3720 - accuracy: 0.8650 - val_loss: 3.7685 - val_accuracy: 0.5156\n",
      "Epoch 176/200\n",
      "1407/1407 [==============================] - 6s 5ms/step - loss: 0.3728 - accuracy: 0.8659 - val_loss: 3.5960 - val_accuracy: 0.5110\n",
      "Epoch 177/200\n",
      "1407/1407 [==============================] - 9s 6ms/step - loss: 0.3639 - accuracy: 0.8669 - val_loss: 3.7333 - val_accuracy: 0.5148\n",
      "Epoch 178/200\n",
      "1407/1407 [==============================] - 10s 7ms/step - loss: 0.3644 - accuracy: 0.8680 - val_loss: 3.7467 - val_accuracy: 0.5144\n",
      "Epoch 179/200\n",
      "1407/1407 [==============================] - 7s 5ms/step - loss: 0.3669 - accuracy: 0.8682 - val_loss: 3.6739 - val_accuracy: 0.5078\n",
      "Epoch 180/200\n",
      "1407/1407 [==============================] - 10s 7ms/step - loss: 0.3692 - accuracy: 0.8657 - val_loss: 3.7900 - val_accuracy: 0.5168\n",
      "Epoch 181/200\n",
      "1407/1407 [==============================] - 8s 5ms/step - loss: 0.3600 - accuracy: 0.8687 - val_loss: 3.9133 - val_accuracy: 0.5070\n",
      "Epoch 182/200\n",
      "1407/1407 [==============================] - 9s 6ms/step - loss: 0.3690 - accuracy: 0.8674 - val_loss: 3.9115 - val_accuracy: 0.5020\n",
      "Epoch 183/200\n",
      "1407/1407 [==============================] - 8s 6ms/step - loss: 0.3589 - accuracy: 0.8705 - val_loss: 3.9642 - val_accuracy: 0.5112\n",
      "Epoch 184/200\n",
      "1407/1407 [==============================] - 6s 4ms/step - loss: 0.3885 - accuracy: 0.8608 - val_loss: 3.8684 - val_accuracy: 0.5116\n",
      "Epoch 185/200\n",
      "1407/1407 [==============================] - 7s 5ms/step - loss: 0.3620 - accuracy: 0.8698 - val_loss: 3.8944 - val_accuracy: 0.5108\n",
      "Epoch 186/200\n",
      "1407/1407 [==============================] - 7s 5ms/step - loss: 0.3628 - accuracy: 0.8690 - val_loss: 3.8438 - val_accuracy: 0.5162\n",
      "Epoch 187/200\n",
      "1407/1407 [==============================] - 8s 6ms/step - loss: 0.3682 - accuracy: 0.8658 - val_loss: 3.9343 - val_accuracy: 0.5114\n",
      "Epoch 188/200\n",
      "1407/1407 [==============================] - 8s 6ms/step - loss: 0.3587 - accuracy: 0.8685 - val_loss: 3.8850 - val_accuracy: 0.5076\n",
      "Epoch 189/200\n",
      "1407/1407 [==============================] - 6s 4ms/step - loss: 0.3722 - accuracy: 0.8668 - val_loss: 3.9469 - val_accuracy: 0.5160\n",
      "Epoch 190/200\n",
      "1407/1407 [==============================] - 8s 6ms/step - loss: 0.3690 - accuracy: 0.8692 - val_loss: 4.0999 - val_accuracy: 0.5108\n",
      "Epoch 191/200\n",
      "1407/1407 [==============================] - 8s 5ms/step - loss: 0.3629 - accuracy: 0.8704 - val_loss: 4.0863 - val_accuracy: 0.5132\n",
      "Epoch 192/200\n",
      "1407/1407 [==============================] - 8s 6ms/step - loss: 0.3581 - accuracy: 0.8714 - val_loss: 3.9954 - val_accuracy: 0.5114\n",
      "Epoch 193/200\n",
      "1407/1407 [==============================] - 8s 6ms/step - loss: 0.3573 - accuracy: 0.8707 - val_loss: 4.0493 - val_accuracy: 0.5148\n",
      "Epoch 194/200\n",
      "1407/1407 [==============================] - 8s 6ms/step - loss: 0.3650 - accuracy: 0.8692 - val_loss: 4.0398 - val_accuracy: 0.5142\n",
      "Epoch 195/200\n",
      "1407/1407 [==============================] - 8s 5ms/step - loss: 0.3615 - accuracy: 0.8699 - val_loss: 3.9137 - val_accuracy: 0.5198\n",
      "Epoch 196/200\n",
      "1407/1407 [==============================] - 8s 6ms/step - loss: 0.3661 - accuracy: 0.8707 - val_loss: 4.0833 - val_accuracy: 0.5082\n",
      "Epoch 197/200\n",
      "1407/1407 [==============================] - 8s 6ms/step - loss: 0.3464 - accuracy: 0.8726 - val_loss: 4.0365 - val_accuracy: 0.5092\n",
      "Epoch 198/200\n",
      "1407/1407 [==============================] - 7s 5ms/step - loss: 0.3706 - accuracy: 0.8674 - val_loss: 4.0097 - val_accuracy: 0.5180\n",
      "Epoch 199/200\n",
      "1407/1407 [==============================] - 8s 6ms/step - loss: 0.3389 - accuracy: 0.8757 - val_loss: 3.9034 - val_accuracy: 0.5214\n",
      "Epoch 200/200\n",
      "1407/1407 [==============================] - 7s 5ms/step - loss: 0.3567 - accuracy: 0.8706 - val_loss: 3.9823 - val_accuracy: 0.5192\n",
      "313/313 [==============================] - 1s 3ms/step - loss: 2429.2783 - accuracy: 0.2420\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[2429.2783203125, 0.24199999868869781]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "batch_size = 32 \n",
    "num_epochs = 200 \n",
    "kernel_size = 3 # использование ядра 3x3 \n",
    "pool_size = 2 # использование объединения 2х2 \n",
    "conv_depth_1 = 32 #  32 ядра на слой преобразования\n",
    "conv_depth_2 = 64 # переход на 64 после первого уровня объединения\n",
    "drop_prob_1 = 0.25 # выбывает после объединения с вероятностью 0,25   мы будем применять dropout после каждого слоя подвыборки, а также после полносвязного слоя;\n",
    "drop_prob_2 = 0.5 # выпадают в плотном слое с вероятностью 0,5\n",
    "hidden_size = 512 # в полносвязном  слое будет 512 нейронов \n",
    "\n",
    "(X_train, y_train), (X_test, y_test) = cifar10.load_data() # извлечение данных CIFAR-10\n",
    "num_train, depth, height, width = X_train.shape # в CIFAR-10 содержится 50000 обучающих примеров\n",
    "num_test = X_test.shape[0] # в CIFAR-10 содержится 10000 тестовых примеров\n",
    "num_classes = np.unique(y_train).shape[0] # существует 10 классов изображений\n",
    "X_train = X_train.astype('float32')\n",
    "X_test = X_test.astype('float32')\n",
    "\n",
    "X_train /= np.max(X_train) # Нормализуйте данные до диапазона [0, 1]\n",
    "X_test /= np.max(X_train) # Нормализуйте данные до диапазона [0, 1]\n",
    "\n",
    "Y_train = np_utils.to_categorical(y_train, num_classes) # кодирование тренировачных данных\n",
    "Y_test = np_utils.to_categorical(y_test, num_classes) # кодирование тестировочных данных\n",
    "\n",
    "\n",
    "inp = Input(shape=(depth, height, width)) # обратите внимание, глубина занимает первое место в Керасе\n",
    "# Conv [32] -> Conv [32] -> Pool (with dropout on the pooling layer)\n",
    "conv_1 = Convolution2D(conv_depth_1, kernel_size, kernel_size,\n",
    "padding='same', activation='relu')(inp) #устарело\n",
    "conv_2 = Convolution2D(conv_depth_1, kernel_size, kernel_size,\n",
    "padding='same', activation='relu')(conv_1)\n",
    "pool_1 = MaxPooling2D(pool_size=(pool_size, pool_size))(conv_2)\n",
    "#drop_1 = Dropout(drop_prob_1)(pool_1)  #Регуляризация – это любая модификация алгоритма обучения, предпринятая с целью уменьшить его ошибку обобщения, не уменьшая ошибку обучения.\n",
    "# Conv [64] -> Conv [64] -> Pool (with dropout on the pooling layer)\n",
    "conv_3 = Convolution2D(conv_depth_2, kernel_size, kernel_size,\n",
    "padding='same', activation='relu')(pool_1)\n",
    "conv_4 = Convolution2D(conv_depth_2, kernel_size, kernel_size,\n",
    "padding='same', activation='relu')(conv_3)\n",
    "pool_2 = MaxPooling2D(pool_size=(pool_size, pool_size),padding='same')(conv_4) # padding='same' входное изображение должно иметь нулевое заполнение, чтобы вывод в свертке не отличался по размеру от ввода. \n",
    "#drop_2 = Dropout(drop_prob_1)(pool_2)\n",
    "#Теперь выровняйте до 1D, примените Плотный -> ReLU (с выпадением) -> softmax\n",
    "flat = Flatten()(pool_2)\n",
    "hidden = Dense(hidden_size, activation='relu')(flat)\n",
    "#drop_3 = Dropout(drop_prob_2)(hidden)\n",
    "out = Dense(num_classes, activation='softmax')(hidden)\n",
    "\n",
    "model = Model(inputs=inp, outputs=out) # Чтобы определить модель, просто укажите ее входные и выходные слои\n",
    "model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy']) \n",
    "model.fit(X_train, Y_train, batch_size=batch_size, epochs=num_epochs, verbose=1, validation_split=0.1) # verbose=1 - индикатор выполнения\n",
    "#model.evaluate прогнозирует значения и вычисляет потери и все прикрепленные метрики к модели по заданному набору данных. \n",
    "model.evaluate(X_test, Y_test, verbose=1) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e1784fbd-7cda-4634-a4f2-db90333cac7c",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/200\n",
      "1407/1407 [==============================] - 16s 11ms/step - loss: 1.8559 - accuracy: 0.2993 - val_loss: 1.6199 - val_accuracy: 0.3956\n",
      "Epoch 2/200\n",
      "1407/1407 [==============================] - 13s 9ms/step - loss: 1.6257 - accuracy: 0.4036 - val_loss: 1.4973 - val_accuracy: 0.4510\n",
      "Epoch 3/200\n",
      "1407/1407 [==============================] - 13s 9ms/step - loss: 1.5330 - accuracy: 0.4383 - val_loss: 1.4136 - val_accuracy: 0.4846\n",
      "Epoch 4/200\n",
      "1407/1407 [==============================] - 14s 10ms/step - loss: 1.4837 - accuracy: 0.4595 - val_loss: 1.3498 - val_accuracy: 0.5120\n",
      "Epoch 5/200\n",
      "1407/1407 [==============================] - 15s 10ms/step - loss: 1.4367 - accuracy: 0.4816 - val_loss: 1.3522 - val_accuracy: 0.5028\n",
      "Epoch 6/200\n",
      "1407/1407 [==============================] - 16s 11ms/step - loss: 1.3951 - accuracy: 0.4953 - val_loss: 1.3233 - val_accuracy: 0.5244\n",
      "Epoch 7/200\n",
      "1407/1407 [==============================] - 12s 8ms/step - loss: 1.3553 - accuracy: 0.5069 - val_loss: 1.2569 - val_accuracy: 0.5420\n",
      "Epoch 8/200\n",
      "1407/1407 [==============================] - 12s 9ms/step - loss: 1.3321 - accuracy: 0.5228 - val_loss: 1.2416 - val_accuracy: 0.5490\n",
      "Epoch 9/200\n",
      "1407/1407 [==============================] - 13s 9ms/step - loss: 1.3094 - accuracy: 0.5269 - val_loss: 1.2439 - val_accuracy: 0.5514\n",
      "Epoch 10/200\n",
      "1407/1407 [==============================] - 14s 10ms/step - loss: 1.2878 - accuracy: 0.5373 - val_loss: 1.2197 - val_accuracy: 0.5616\n",
      "Epoch 11/200\n",
      "1407/1407 [==============================] - 14s 10ms/step - loss: 1.2726 - accuracy: 0.5444 - val_loss: 1.2289 - val_accuracy: 0.5484\n",
      "Epoch 12/200\n",
      "1407/1407 [==============================] - 14s 10ms/step - loss: 1.2589 - accuracy: 0.5500 - val_loss: 1.2177 - val_accuracy: 0.5476\n",
      "Epoch 13/200\n",
      "1407/1407 [==============================] - 14s 10ms/step - loss: 1.2392 - accuracy: 0.5573 - val_loss: 1.2403 - val_accuracy: 0.5614\n",
      "Epoch 14/200\n",
      "1407/1407 [==============================] - 12s 9ms/step - loss: 1.2261 - accuracy: 0.5616 - val_loss: 1.1902 - val_accuracy: 0.5754\n",
      "Epoch 15/200\n",
      "1407/1407 [==============================] - 11s 8ms/step - loss: 1.2089 - accuracy: 0.5686 - val_loss: 1.1815 - val_accuracy: 0.5784\n",
      "Epoch 16/200\n",
      "1407/1407 [==============================] - 11s 8ms/step - loss: 1.1986 - accuracy: 0.5733 - val_loss: 1.1807 - val_accuracy: 0.5654\n",
      "Epoch 17/200\n",
      "1407/1407 [==============================] - 10s 7ms/step - loss: 1.1900 - accuracy: 0.5744 - val_loss: 1.1846 - val_accuracy: 0.5756\n",
      "Epoch 18/200\n",
      "1407/1407 [==============================] - 11s 8ms/step - loss: 1.1750 - accuracy: 0.5825 - val_loss: 1.1946 - val_accuracy: 0.5752\n",
      "Epoch 19/200\n",
      "1407/1407 [==============================] - 20s 14ms/step - loss: 1.1655 - accuracy: 0.5834 - val_loss: 1.1574 - val_accuracy: 0.5808\n",
      "Epoch 20/200\n",
      "1407/1407 [==============================] - 17s 12ms/step - loss: 1.1583 - accuracy: 0.5871 - val_loss: 1.1564 - val_accuracy: 0.5760\n",
      "Epoch 21/200\n",
      "1407/1407 [==============================] - 13s 9ms/step - loss: 1.1451 - accuracy: 0.5930 - val_loss: 1.1445 - val_accuracy: 0.5836\n",
      "Epoch 22/200\n",
      "1407/1407 [==============================] - 13s 9ms/step - loss: 1.1457 - accuracy: 0.5936 - val_loss: 1.1727 - val_accuracy: 0.5776\n",
      "Epoch 23/200\n",
      "1407/1407 [==============================] - 20s 14ms/step - loss: 1.1304 - accuracy: 0.5992 - val_loss: 1.1900 - val_accuracy: 0.5728\n",
      "Epoch 24/200\n",
      "1407/1407 [==============================] - 13s 9ms/step - loss: 1.1292 - accuracy: 0.5974 - val_loss: 1.1700 - val_accuracy: 0.5812\n",
      "Epoch 25/200\n",
      "1407/1407 [==============================] - 14s 10ms/step - loss: 1.1189 - accuracy: 0.6036 - val_loss: 1.1639 - val_accuracy: 0.5832\n",
      "Epoch 26/200\n",
      "1407/1407 [==============================] - 15s 10ms/step - loss: 1.1097 - accuracy: 0.6072 - val_loss: 1.1450 - val_accuracy: 0.5830\n",
      "Epoch 27/200\n",
      "1407/1407 [==============================] - 22s 16ms/step - loss: 1.1019 - accuracy: 0.6092 - val_loss: 1.1384 - val_accuracy: 0.5936\n",
      "Epoch 28/200\n",
      "1407/1407 [==============================] - 17s 12ms/step - loss: 1.1025 - accuracy: 0.6087 - val_loss: 1.1636 - val_accuracy: 0.5850\n",
      "Epoch 29/200\n",
      "1407/1407 [==============================] - 11s 8ms/step - loss: 1.0913 - accuracy: 0.6109 - val_loss: 1.1758 - val_accuracy: 0.5798\n",
      "Epoch 30/200\n",
      "1407/1407 [==============================] - 11s 8ms/step - loss: 1.0857 - accuracy: 0.6145 - val_loss: 1.1639 - val_accuracy: 0.5858\n",
      "Epoch 31/200\n",
      "1407/1407 [==============================] - 14s 10ms/step - loss: 1.0772 - accuracy: 0.6179 - val_loss: 1.1374 - val_accuracy: 0.5916\n",
      "Epoch 32/200\n",
      "1407/1407 [==============================] - 15s 11ms/step - loss: 1.0745 - accuracy: 0.6190 - val_loss: 1.1834 - val_accuracy: 0.5768\n",
      "Epoch 33/200\n",
      "1407/1407 [==============================] - 13s 9ms/step - loss: 1.0741 - accuracy: 0.6210 - val_loss: 1.1280 - val_accuracy: 0.5966\n",
      "Epoch 34/200\n",
      "1407/1407 [==============================] - 15s 11ms/step - loss: 1.0641 - accuracy: 0.6240 - val_loss: 1.1531 - val_accuracy: 0.5918\n",
      "Epoch 35/200\n",
      "1407/1407 [==============================] - 13s 9ms/step - loss: 1.0641 - accuracy: 0.6231 - val_loss: 1.1486 - val_accuracy: 0.5856\n",
      "Epoch 36/200\n",
      "1407/1407 [==============================] - 13s 10ms/step - loss: 1.0575 - accuracy: 0.6245 - val_loss: 1.1591 - val_accuracy: 0.5836\n",
      "Epoch 37/200\n",
      "1407/1407 [==============================] - 14s 10ms/step - loss: 1.0541 - accuracy: 0.6289 - val_loss: 1.1371 - val_accuracy: 0.5950\n",
      "Epoch 38/200\n",
      "1407/1407 [==============================] - 13s 9ms/step - loss: 1.0498 - accuracy: 0.6272 - val_loss: 1.1446 - val_accuracy: 0.5908\n",
      "Epoch 39/200\n",
      "1407/1407 [==============================] - 12s 9ms/step - loss: 1.0417 - accuracy: 0.6310 - val_loss: 1.1336 - val_accuracy: 0.5922\n",
      "Epoch 40/200\n",
      "1407/1407 [==============================] - 15s 11ms/step - loss: 1.0478 - accuracy: 0.6300 - val_loss: 1.1378 - val_accuracy: 0.5994\n",
      "Epoch 41/200\n",
      "1407/1407 [==============================] - 11s 8ms/step - loss: 1.0330 - accuracy: 0.6347 - val_loss: 1.1308 - val_accuracy: 0.5950\n",
      "Epoch 42/200\n",
      "1407/1407 [==============================] - 13s 9ms/step - loss: 1.0281 - accuracy: 0.6379 - val_loss: 1.1249 - val_accuracy: 0.5928\n",
      "Epoch 43/200\n",
      "1407/1407 [==============================] - 14s 10ms/step - loss: 1.0266 - accuracy: 0.6373 - val_loss: 1.1305 - val_accuracy: 0.5948\n",
      "Epoch 44/200\n",
      "1407/1407 [==============================] - 13s 9ms/step - loss: 1.0238 - accuracy: 0.6386 - val_loss: 1.1415 - val_accuracy: 0.5902\n",
      "Epoch 45/200\n",
      "1407/1407 [==============================] - 15s 11ms/step - loss: 1.0170 - accuracy: 0.6428 - val_loss: 1.1448 - val_accuracy: 0.5982\n",
      "Epoch 46/200\n",
      "1407/1407 [==============================] - 16s 12ms/step - loss: 1.0154 - accuracy: 0.6399 - val_loss: 1.1474 - val_accuracy: 0.5944\n",
      "Epoch 47/200\n",
      "1407/1407 [==============================] - 14s 10ms/step - loss: 1.0094 - accuracy: 0.6418 - val_loss: 1.1301 - val_accuracy: 0.5926\n",
      "Epoch 48/200\n",
      "1407/1407 [==============================] - 14s 10ms/step - loss: 1.0167 - accuracy: 0.6408 - val_loss: 1.1426 - val_accuracy: 0.5880\n",
      "Epoch 49/200\n",
      "1407/1407 [==============================] - 15s 11ms/step - loss: 1.0070 - accuracy: 0.6448 - val_loss: 1.1432 - val_accuracy: 0.5922\n",
      "Epoch 50/200\n",
      "1407/1407 [==============================] - 15s 11ms/step - loss: 1.0031 - accuracy: 0.6442 - val_loss: 1.1460 - val_accuracy: 0.5880\n",
      "Epoch 51/200\n",
      "1407/1407 [==============================] - 11s 8ms/step - loss: 0.9936 - accuracy: 0.6492 - val_loss: 1.1477 - val_accuracy: 0.5926\n",
      "Epoch 52/200\n",
      "1407/1407 [==============================] - 13s 10ms/step - loss: 0.9964 - accuracy: 0.6452 - val_loss: 1.1478 - val_accuracy: 0.5966\n",
      "Epoch 53/200\n",
      "1407/1407 [==============================] - 20s 14ms/step - loss: 0.9920 - accuracy: 0.6506 - val_loss: 1.1405 - val_accuracy: 0.5910\n",
      "Epoch 54/200\n",
      "1407/1407 [==============================] - 20s 14ms/step - loss: 0.9893 - accuracy: 0.6529 - val_loss: 1.1212 - val_accuracy: 0.6000\n",
      "Epoch 55/200\n",
      "1407/1407 [==============================] - 10s 7ms/step - loss: 0.9851 - accuracy: 0.6525 - val_loss: 1.1236 - val_accuracy: 0.5962\n",
      "Epoch 56/200\n",
      "1407/1407 [==============================] - 11s 8ms/step - loss: 0.9869 - accuracy: 0.6528 - val_loss: 1.1296 - val_accuracy: 0.6004\n",
      "Epoch 57/200\n",
      "1407/1407 [==============================] - 10s 7ms/step - loss: 0.9818 - accuracy: 0.6539 - val_loss: 1.1192 - val_accuracy: 0.6056\n",
      "Epoch 58/200\n",
      "1407/1407 [==============================] - 11s 8ms/step - loss: 0.9771 - accuracy: 0.6572 - val_loss: 1.1239 - val_accuracy: 0.6038\n",
      "Epoch 59/200\n",
      "1407/1407 [==============================] - 17s 12ms/step - loss: 0.9749 - accuracy: 0.6569 - val_loss: 1.1163 - val_accuracy: 0.6042\n",
      "Epoch 60/200\n",
      "1407/1407 [==============================] - 13s 9ms/step - loss: 0.9729 - accuracy: 0.6574 - val_loss: 1.1515 - val_accuracy: 0.5912\n",
      "Epoch 61/200\n",
      "1407/1407 [==============================] - 14s 10ms/step - loss: 0.9682 - accuracy: 0.6582 - val_loss: 1.1477 - val_accuracy: 0.5898\n",
      "Epoch 62/200\n",
      "1407/1407 [==============================] - 15s 11ms/step - loss: 0.9662 - accuracy: 0.6599 - val_loss: 1.1243 - val_accuracy: 0.6010\n",
      "Epoch 63/200\n",
      "1407/1407 [==============================] - 15s 11ms/step - loss: 0.9606 - accuracy: 0.6640 - val_loss: 1.1459 - val_accuracy: 0.5980\n",
      "Epoch 64/200\n",
      "1407/1407 [==============================] - 19s 13ms/step - loss: 0.9617 - accuracy: 0.6615 - val_loss: 1.1426 - val_accuracy: 0.5988\n",
      "Epoch 65/200\n",
      "1407/1407 [==============================] - 17s 12ms/step - loss: 0.9662 - accuracy: 0.6596 - val_loss: 1.1570 - val_accuracy: 0.5884\n",
      "Epoch 66/200\n",
      "1407/1407 [==============================] - 14s 10ms/step - loss: 0.9707 - accuracy: 0.6592 - val_loss: 1.1493 - val_accuracy: 0.5944\n",
      "Epoch 67/200\n",
      "1407/1407 [==============================] - 13s 9ms/step - loss: 0.9565 - accuracy: 0.6669 - val_loss: 1.1672 - val_accuracy: 0.5872\n",
      "Epoch 68/200\n",
      "1407/1407 [==============================] - 12s 9ms/step - loss: 0.9485 - accuracy: 0.6674 - val_loss: 1.1405 - val_accuracy: 0.5986\n",
      "Epoch 69/200\n",
      "1407/1407 [==============================] - 15s 10ms/step - loss: 0.9462 - accuracy: 0.6675 - val_loss: 1.1280 - val_accuracy: 0.6044\n",
      "Epoch 70/200\n",
      "1407/1407 [==============================] - 14s 10ms/step - loss: 0.9526 - accuracy: 0.6666 - val_loss: 1.1631 - val_accuracy: 0.5900\n",
      "Epoch 71/200\n",
      "1407/1407 [==============================] - 13s 9ms/step - loss: 0.9496 - accuracy: 0.6676 - val_loss: 1.1154 - val_accuracy: 0.6036\n",
      "Epoch 72/200\n",
      "1407/1407 [==============================] - 15s 10ms/step - loss: 0.9454 - accuracy: 0.6686 - val_loss: 1.1305 - val_accuracy: 0.5992\n",
      "Epoch 73/200\n",
      "1407/1407 [==============================] - 12s 9ms/step - loss: 0.9459 - accuracy: 0.6686 - val_loss: 1.1402 - val_accuracy: 0.5982\n",
      "Epoch 74/200\n",
      "1407/1407 [==============================] - 11s 8ms/step - loss: 0.9471 - accuracy: 0.6675 - val_loss: 1.1570 - val_accuracy: 0.5958\n",
      "Epoch 75/200\n",
      "1407/1407 [==============================] - 11s 8ms/step - loss: 0.9352 - accuracy: 0.6727 - val_loss: 1.1318 - val_accuracy: 0.6068\n",
      "Epoch 76/200\n",
      "1407/1407 [==============================] - 13s 9ms/step - loss: 0.9448 - accuracy: 0.6700 - val_loss: 1.1413 - val_accuracy: 0.5994\n",
      "Epoch 77/200\n",
      "1407/1407 [==============================] - 14s 10ms/step - loss: 0.9409 - accuracy: 0.6690 - val_loss: 1.1581 - val_accuracy: 0.5928\n",
      "Epoch 78/200\n",
      "1407/1407 [==============================] - 15s 11ms/step - loss: 0.9315 - accuracy: 0.6736 - val_loss: 1.1447 - val_accuracy: 0.6038\n",
      "Epoch 79/200\n",
      "1407/1407 [==============================] - 15s 10ms/step - loss: 0.9419 - accuracy: 0.6704 - val_loss: 1.1659 - val_accuracy: 0.5868\n",
      "Epoch 80/200\n",
      "1407/1407 [==============================] - 13s 9ms/step - loss: 0.9298 - accuracy: 0.6740 - val_loss: 1.1393 - val_accuracy: 0.5974\n",
      "Epoch 81/200\n",
      "1407/1407 [==============================] - 12s 9ms/step - loss: 0.9258 - accuracy: 0.6754 - val_loss: 1.1600 - val_accuracy: 0.5952\n",
      "Epoch 82/200\n",
      "1407/1407 [==============================] - 15s 11ms/step - loss: 0.9265 - accuracy: 0.6757 - val_loss: 1.1502 - val_accuracy: 0.5930\n",
      "Epoch 83/200\n",
      "1407/1407 [==============================] - 13s 10ms/step - loss: 0.9275 - accuracy: 0.6757 - val_loss: 1.1458 - val_accuracy: 0.6010\n",
      "Epoch 84/200\n",
      "1407/1407 [==============================] - 11s 8ms/step - loss: 0.9187 - accuracy: 0.6779 - val_loss: 1.1269 - val_accuracy: 0.6018\n",
      "Epoch 85/200\n",
      "1407/1407 [==============================] - 10s 7ms/step - loss: 0.9171 - accuracy: 0.6800 - val_loss: 1.1666 - val_accuracy: 0.5952\n",
      "Epoch 86/200\n",
      "1407/1407 [==============================] - 13s 9ms/step - loss: 0.9251 - accuracy: 0.6787 - val_loss: 1.1378 - val_accuracy: 0.6064\n",
      "Epoch 87/200\n",
      "1407/1407 [==============================] - 12s 8ms/step - loss: 0.9238 - accuracy: 0.6781 - val_loss: 1.1475 - val_accuracy: 0.6016\n",
      "Epoch 88/200\n",
      "1407/1407 [==============================] - 10s 7ms/step - loss: 0.9188 - accuracy: 0.6786 - val_loss: 1.1510 - val_accuracy: 0.5972\n",
      "Epoch 89/200\n",
      "1407/1407 [==============================] - 11s 7ms/step - loss: 0.9164 - accuracy: 0.6799 - val_loss: 1.1750 - val_accuracy: 0.5870\n",
      "Epoch 90/200\n",
      "1407/1407 [==============================] - 13s 9ms/step - loss: 0.9119 - accuracy: 0.6817 - val_loss: 1.1518 - val_accuracy: 0.5976\n",
      "Epoch 91/200\n",
      "1407/1407 [==============================] - 9s 7ms/step - loss: 0.9173 - accuracy: 0.6818 - val_loss: 1.1511 - val_accuracy: 0.5972\n",
      "Epoch 92/200\n",
      "1407/1407 [==============================] - 10s 7ms/step - loss: 0.9118 - accuracy: 0.6810 - val_loss: 1.1512 - val_accuracy: 0.5956\n",
      "Epoch 93/200\n",
      "1407/1407 [==============================] - 11s 8ms/step - loss: 0.9106 - accuracy: 0.6820 - val_loss: 1.1708 - val_accuracy: 0.5906\n",
      "Epoch 94/200\n",
      "1407/1407 [==============================] - 9s 7ms/step - loss: 0.9162 - accuracy: 0.6802 - val_loss: 1.1554 - val_accuracy: 0.6006\n",
      "Epoch 95/200\n",
      "1407/1407 [==============================] - 12s 8ms/step - loss: 0.9131 - accuracy: 0.6842 - val_loss: 1.1680 - val_accuracy: 0.5982\n",
      "Epoch 96/200\n",
      "1407/1407 [==============================] - 13s 9ms/step - loss: 0.9038 - accuracy: 0.6843 - val_loss: 1.1434 - val_accuracy: 0.6034\n",
      "Epoch 97/200\n",
      "1407/1407 [==============================] - 14s 10ms/step - loss: 0.9088 - accuracy: 0.6855 - val_loss: 1.1534 - val_accuracy: 0.5908\n",
      "Epoch 98/200\n",
      "1407/1407 [==============================] - 13s 9ms/step - loss: 0.9078 - accuracy: 0.6832 - val_loss: 1.1581 - val_accuracy: 0.5962\n",
      "Epoch 99/200\n",
      "1407/1407 [==============================] - 12s 9ms/step - loss: 0.8989 - accuracy: 0.6849 - val_loss: 1.1554 - val_accuracy: 0.5978\n",
      "Epoch 100/200\n",
      "1407/1407 [==============================] - 13s 9ms/step - loss: 0.9066 - accuracy: 0.6810 - val_loss: 1.1823 - val_accuracy: 0.5818\n",
      "Epoch 101/200\n",
      "1407/1407 [==============================] - 13s 9ms/step - loss: 0.8950 - accuracy: 0.6889 - val_loss: 1.1622 - val_accuracy: 0.5964\n",
      "Epoch 102/200\n",
      "1407/1407 [==============================] - 13s 9ms/step - loss: 0.8975 - accuracy: 0.6878 - val_loss: 1.1607 - val_accuracy: 0.5978\n",
      "Epoch 103/200\n",
      "1407/1407 [==============================] - 10s 7ms/step - loss: 0.8958 - accuracy: 0.6887 - val_loss: 1.1636 - val_accuracy: 0.5922\n",
      "Epoch 104/200\n",
      "1407/1407 [==============================] - 10s 7ms/step - loss: 0.8965 - accuracy: 0.6874 - val_loss: 1.1645 - val_accuracy: 0.5900\n",
      "Epoch 105/200\n",
      "1407/1407 [==============================] - 10s 7ms/step - loss: 0.9019 - accuracy: 0.6858 - val_loss: 1.1625 - val_accuracy: 0.6002\n",
      "Epoch 106/200\n",
      "1407/1407 [==============================] - 13s 9ms/step - loss: 0.8964 - accuracy: 0.6887 - val_loss: 1.1585 - val_accuracy: 0.5964\n",
      "Epoch 107/200\n",
      "1407/1407 [==============================] - 14s 10ms/step - loss: 0.8894 - accuracy: 0.6928 - val_loss: 1.1848 - val_accuracy: 0.5946\n",
      "Epoch 108/200\n",
      "1407/1407 [==============================] - 12s 9ms/step - loss: 0.8928 - accuracy: 0.6895 - val_loss: 1.1573 - val_accuracy: 0.5988\n",
      "Epoch 109/200\n",
      "1407/1407 [==============================] - 12s 8ms/step - loss: 0.8918 - accuracy: 0.6899 - val_loss: 1.1830 - val_accuracy: 0.5906\n",
      "Epoch 110/200\n",
      "1407/1407 [==============================] - 13s 9ms/step - loss: 0.8954 - accuracy: 0.6902 - val_loss: 1.1533 - val_accuracy: 0.5970\n",
      "Epoch 111/200\n",
      "1407/1407 [==============================] - 10s 7ms/step - loss: 0.8863 - accuracy: 0.6916 - val_loss: 1.1905 - val_accuracy: 0.5952\n",
      "Epoch 112/200\n",
      "1407/1407 [==============================] - 11s 8ms/step - loss: 0.8875 - accuracy: 0.6898 - val_loss: 1.1622 - val_accuracy: 0.5956\n",
      "Epoch 113/200\n",
      "1407/1407 [==============================] - 10s 7ms/step - loss: 0.8858 - accuracy: 0.6915 - val_loss: 1.1853 - val_accuracy: 0.5882\n",
      "Epoch 114/200\n",
      "1407/1407 [==============================] - 9s 7ms/step - loss: 0.8834 - accuracy: 0.6932 - val_loss: 1.1791 - val_accuracy: 0.5870\n",
      "Epoch 115/200\n",
      "1407/1407 [==============================] - 10s 7ms/step - loss: 0.8904 - accuracy: 0.6908 - val_loss: 1.1786 - val_accuracy: 0.5936\n",
      "Epoch 116/200\n",
      "1407/1407 [==============================] - 9s 7ms/step - loss: 0.8866 - accuracy: 0.6929 - val_loss: 1.1866 - val_accuracy: 0.5920\n",
      "Epoch 117/200\n",
      "1407/1407 [==============================] - 9s 6ms/step - loss: 0.8803 - accuracy: 0.6950 - val_loss: 1.1714 - val_accuracy: 0.5950\n",
      "Epoch 118/200\n",
      "1407/1407 [==============================] - 10s 7ms/step - loss: 0.8792 - accuracy: 0.6949 - val_loss: 1.1892 - val_accuracy: 0.5942\n",
      "Epoch 119/200\n",
      "1407/1407 [==============================] - 12s 8ms/step - loss: 0.8839 - accuracy: 0.6903 - val_loss: 1.1530 - val_accuracy: 0.6068\n",
      "Epoch 120/200\n",
      "1407/1407 [==============================] - 10s 7ms/step - loss: 0.8836 - accuracy: 0.6919 - val_loss: 1.1777 - val_accuracy: 0.5988\n",
      "Epoch 121/200\n",
      "1407/1407 [==============================] - 12s 9ms/step - loss: 0.8778 - accuracy: 0.6930 - val_loss: 1.1750 - val_accuracy: 0.5922\n",
      "Epoch 122/200\n",
      "1407/1407 [==============================] - 13s 9ms/step - loss: 0.8831 - accuracy: 0.6938 - val_loss: 1.1631 - val_accuracy: 0.6008\n",
      "Epoch 123/200\n",
      "1407/1407 [==============================] - 11s 8ms/step - loss: 0.8792 - accuracy: 0.6956 - val_loss: 1.1634 - val_accuracy: 0.5968\n",
      "Epoch 124/200\n",
      "1407/1407 [==============================] - 12s 9ms/step - loss: 0.8719 - accuracy: 0.6975 - val_loss: 1.1779 - val_accuracy: 0.5900\n",
      "Epoch 125/200\n",
      "1407/1407 [==============================] - 11s 8ms/step - loss: 0.8732 - accuracy: 0.6966 - val_loss: 1.2008 - val_accuracy: 0.5870\n",
      "Epoch 126/200\n",
      "1407/1407 [==============================] - 11s 8ms/step - loss: 0.8662 - accuracy: 0.7006 - val_loss: 1.1955 - val_accuracy: 0.5876\n",
      "Epoch 127/200\n",
      "1407/1407 [==============================] - 10s 7ms/step - loss: 0.8779 - accuracy: 0.6944 - val_loss: 1.1840 - val_accuracy: 0.5908\n",
      "Epoch 128/200\n",
      "1407/1407 [==============================] - 10s 7ms/step - loss: 0.8745 - accuracy: 0.6951 - val_loss: 1.1783 - val_accuracy: 0.5944\n",
      "Epoch 129/200\n",
      "1407/1407 [==============================] - 10s 7ms/step - loss: 0.8648 - accuracy: 0.7021 - val_loss: 1.1852 - val_accuracy: 0.5926\n",
      "Epoch 130/200\n",
      "1407/1407 [==============================] - 10s 7ms/step - loss: 0.8705 - accuracy: 0.6963 - val_loss: 1.2024 - val_accuracy: 0.5872\n",
      "Epoch 131/200\n",
      "1407/1407 [==============================] - 10s 7ms/step - loss: 0.8718 - accuracy: 0.6959 - val_loss: 1.1861 - val_accuracy: 0.5902\n",
      "Epoch 132/200\n",
      "1407/1407 [==============================] - 10s 7ms/step - loss: 0.8602 - accuracy: 0.7024 - val_loss: 1.1561 - val_accuracy: 0.6044\n",
      "Epoch 133/200\n",
      "1407/1407 [==============================] - 11s 8ms/step - loss: 0.8557 - accuracy: 0.7022 - val_loss: 1.1846 - val_accuracy: 0.5964\n",
      "Epoch 134/200\n",
      "1407/1407 [==============================] - 11s 7ms/step - loss: 0.8697 - accuracy: 0.7010 - val_loss: 1.1707 - val_accuracy: 0.5904\n",
      "Epoch 135/200\n",
      "1407/1407 [==============================] - 11s 8ms/step - loss: 0.8623 - accuracy: 0.7014 - val_loss: 1.1801 - val_accuracy: 0.5914\n",
      "Epoch 136/200\n",
      "1407/1407 [==============================] - 11s 8ms/step - loss: 0.8710 - accuracy: 0.6991 - val_loss: 1.1818 - val_accuracy: 0.5970\n",
      "Epoch 137/200\n",
      "1407/1407 [==============================] - 12s 9ms/step - loss: 0.8597 - accuracy: 0.7019 - val_loss: 1.1979 - val_accuracy: 0.5878\n",
      "Epoch 138/200\n",
      "1407/1407 [==============================] - 12s 9ms/step - loss: 0.8551 - accuracy: 0.7051 - val_loss: 1.1883 - val_accuracy: 0.5922\n",
      "Epoch 139/200\n",
      "1407/1407 [==============================] - 12s 9ms/step - loss: 0.8656 - accuracy: 0.7004 - val_loss: 1.1785 - val_accuracy: 0.5886\n",
      "Epoch 140/200\n",
      "1407/1407 [==============================] - 11s 8ms/step - loss: 0.8657 - accuracy: 0.7011 - val_loss: 1.1920 - val_accuracy: 0.5886\n",
      "Epoch 141/200\n",
      "1407/1407 [==============================] - 9s 7ms/step - loss: 0.8649 - accuracy: 0.7031 - val_loss: 1.1855 - val_accuracy: 0.5874\n",
      "Epoch 142/200\n",
      "1407/1407 [==============================] - 11s 8ms/step - loss: 0.8505 - accuracy: 0.7004 - val_loss: 1.2001 - val_accuracy: 0.5878\n",
      "Epoch 143/200\n",
      "1407/1407 [==============================] - 46s 33ms/step - loss: 0.8457 - accuracy: 0.7048 - val_loss: 1.1881 - val_accuracy: 0.5882\n",
      "Epoch 144/200\n",
      "1407/1407 [==============================] - 55s 39ms/step - loss: 0.8487 - accuracy: 0.7072 - val_loss: 1.1805 - val_accuracy: 0.5910\n",
      "Epoch 145/200\n",
      "1407/1407 [==============================] - 57s 40ms/step - loss: 0.8591 - accuracy: 0.7026 - val_loss: 1.1854 - val_accuracy: 0.5892\n",
      "Epoch 146/200\n",
      "1407/1407 [==============================] - 29s 21ms/step - loss: 0.8479 - accuracy: 0.7076 - val_loss: 1.1902 - val_accuracy: 0.5976\n",
      "Epoch 147/200\n",
      "1407/1407 [==============================] - 10s 7ms/step - loss: 0.8538 - accuracy: 0.7042 - val_loss: 1.1750 - val_accuracy: 0.5906\n",
      "Epoch 148/200\n",
      "1407/1407 [==============================] - 11s 8ms/step - loss: 0.8443 - accuracy: 0.7075 - val_loss: 1.1863 - val_accuracy: 0.5978\n",
      "Epoch 149/200\n",
      "1407/1407 [==============================] - 11s 8ms/step - loss: 0.8524 - accuracy: 0.7061 - val_loss: 1.2015 - val_accuracy: 0.5904\n",
      "Epoch 150/200\n",
      "1407/1407 [==============================] - 12s 8ms/step - loss: 0.8419 - accuracy: 0.7088 - val_loss: 1.1796 - val_accuracy: 0.5912\n",
      "Epoch 151/200\n",
      "1407/1407 [==============================] - 10s 7ms/step - loss: 0.8540 - accuracy: 0.7061 - val_loss: 1.1974 - val_accuracy: 0.5774\n",
      "Epoch 152/200\n",
      "1407/1407 [==============================] - 10s 7ms/step - loss: 0.8458 - accuracy: 0.7057 - val_loss: 1.1962 - val_accuracy: 0.5916\n",
      "Epoch 153/200\n",
      "1407/1407 [==============================] - 12s 8ms/step - loss: 0.8509 - accuracy: 0.7052 - val_loss: 1.1693 - val_accuracy: 0.5950\n",
      "Epoch 154/200\n",
      "1407/1407 [==============================] - 13s 9ms/step - loss: 0.8452 - accuracy: 0.7071 - val_loss: 1.1879 - val_accuracy: 0.5876\n",
      "Epoch 155/200\n",
      "1407/1407 [==============================] - 11s 8ms/step - loss: 0.8450 - accuracy: 0.7104 - val_loss: 1.1810 - val_accuracy: 0.5898\n",
      "Epoch 156/200\n",
      "1407/1407 [==============================] - 11s 8ms/step - loss: 0.8406 - accuracy: 0.7079 - val_loss: 1.1868 - val_accuracy: 0.5898\n",
      "Epoch 157/200\n",
      "1407/1407 [==============================] - 12s 9ms/step - loss: 0.8386 - accuracy: 0.7103 - val_loss: 1.2095 - val_accuracy: 0.5920\n",
      "Epoch 158/200\n",
      "1407/1407 [==============================] - 11s 8ms/step - loss: 0.8441 - accuracy: 0.7076 - val_loss: 1.1853 - val_accuracy: 0.5912\n",
      "Epoch 159/200\n",
      "1407/1407 [==============================] - 12s 8ms/step - loss: 0.8438 - accuracy: 0.7087 - val_loss: 1.1819 - val_accuracy: 0.5940\n",
      "Epoch 160/200\n",
      "1407/1407 [==============================] - 11s 8ms/step - loss: 0.8351 - accuracy: 0.7110 - val_loss: 1.1822 - val_accuracy: 0.5964\n",
      "Epoch 161/200\n",
      "1407/1407 [==============================] - 12s 9ms/step - loss: 0.8379 - accuracy: 0.7084 - val_loss: 1.2061 - val_accuracy: 0.5922\n",
      "Epoch 162/200\n",
      "1407/1407 [==============================] - 14s 10ms/step - loss: 0.8512 - accuracy: 0.7080 - val_loss: 1.1889 - val_accuracy: 0.5954\n",
      "Epoch 163/200\n",
      "1407/1407 [==============================] - 12s 9ms/step - loss: 0.8338 - accuracy: 0.7143 - val_loss: 1.2010 - val_accuracy: 0.5936\n",
      "Epoch 164/200\n",
      "1407/1407 [==============================] - 13s 9ms/step - loss: 0.8409 - accuracy: 0.7110 - val_loss: 1.1858 - val_accuracy: 0.6058\n",
      "Epoch 165/200\n",
      "1407/1407 [==============================] - 10s 7ms/step - loss: 0.8430 - accuracy: 0.7132 - val_loss: 1.1991 - val_accuracy: 0.5906\n",
      "Epoch 166/200\n",
      "1407/1407 [==============================] - 10s 7ms/step - loss: 0.8330 - accuracy: 0.7132 - val_loss: 1.1997 - val_accuracy: 0.5906\n",
      "Epoch 167/200\n",
      "1407/1407 [==============================] - 12s 8ms/step - loss: 0.8379 - accuracy: 0.7103 - val_loss: 1.2159 - val_accuracy: 0.5922\n",
      "Epoch 168/200\n",
      "1407/1407 [==============================] - 11s 8ms/step - loss: 0.8336 - accuracy: 0.7128 - val_loss: 1.1958 - val_accuracy: 0.5926\n",
      "Epoch 169/200\n",
      "1407/1407 [==============================] - 13s 9ms/step - loss: 0.8347 - accuracy: 0.7140 - val_loss: 1.1915 - val_accuracy: 0.5950\n",
      "Epoch 170/200\n",
      "1407/1407 [==============================] - 10s 7ms/step - loss: 0.8256 - accuracy: 0.7148 - val_loss: 1.2102 - val_accuracy: 0.5868\n",
      "Epoch 171/200\n",
      "1407/1407 [==============================] - 10s 7ms/step - loss: 0.8349 - accuracy: 0.7158 - val_loss: 1.2018 - val_accuracy: 0.5922\n",
      "Epoch 172/200\n",
      "1407/1407 [==============================] - 11s 8ms/step - loss: 0.8403 - accuracy: 0.7112 - val_loss: 1.2088 - val_accuracy: 0.5912\n",
      "Epoch 173/200\n",
      "1407/1407 [==============================] - 10s 7ms/step - loss: 0.8260 - accuracy: 0.7174 - val_loss: 1.1929 - val_accuracy: 0.5926\n",
      "Epoch 174/200\n",
      "1407/1407 [==============================] - 10s 7ms/step - loss: 0.8335 - accuracy: 0.7154 - val_loss: 1.1829 - val_accuracy: 0.5994\n",
      "Epoch 175/200\n",
      "1407/1407 [==============================] - 12s 9ms/step - loss: 0.8318 - accuracy: 0.7142 - val_loss: 1.1954 - val_accuracy: 0.5936\n",
      "Epoch 176/200\n",
      "1407/1407 [==============================] - 10s 7ms/step - loss: 0.8256 - accuracy: 0.7151 - val_loss: 1.2012 - val_accuracy: 0.5916\n",
      "Epoch 177/200\n",
      "1407/1407 [==============================] - 13s 9ms/step - loss: 0.8207 - accuracy: 0.7185 - val_loss: 1.2035 - val_accuracy: 0.5818\n",
      "Epoch 178/200\n",
      "1407/1407 [==============================] - 10s 7ms/step - loss: 0.8286 - accuracy: 0.7164 - val_loss: 1.1917 - val_accuracy: 0.5910\n",
      "Epoch 179/200\n",
      "1407/1407 [==============================] - 12s 9ms/step - loss: 0.8309 - accuracy: 0.7144 - val_loss: 1.1908 - val_accuracy: 0.5964\n",
      "Epoch 180/200\n",
      "1407/1407 [==============================] - 11s 8ms/step - loss: 0.8288 - accuracy: 0.7141 - val_loss: 1.2111 - val_accuracy: 0.5924\n",
      "Epoch 181/200\n",
      "1407/1407 [==============================] - 11s 8ms/step - loss: 0.8374 - accuracy: 0.7130 - val_loss: 1.1964 - val_accuracy: 0.5992\n",
      "Epoch 182/200\n",
      "1407/1407 [==============================] - 10s 7ms/step - loss: 0.8212 - accuracy: 0.7175 - val_loss: 1.2189 - val_accuracy: 0.5888\n",
      "Epoch 183/200\n",
      "1407/1407 [==============================] - 11s 8ms/step - loss: 0.8265 - accuracy: 0.7192 - val_loss: 1.1784 - val_accuracy: 0.5932\n",
      "Epoch 184/200\n",
      "1407/1407 [==============================] - 12s 9ms/step - loss: 0.8288 - accuracy: 0.7151 - val_loss: 1.2088 - val_accuracy: 0.5900\n",
      "Epoch 185/200\n",
      "1407/1407 [==============================] - 10s 7ms/step - loss: 0.8231 - accuracy: 0.7170 - val_loss: 1.1918 - val_accuracy: 0.5960\n",
      "Epoch 186/200\n",
      "1407/1407 [==============================] - 10s 7ms/step - loss: 0.8199 - accuracy: 0.7168 - val_loss: 1.1934 - val_accuracy: 0.5928\n",
      "Epoch 187/200\n",
      "1407/1407 [==============================] - 10s 7ms/step - loss: 0.8281 - accuracy: 0.7123 - val_loss: 1.2258 - val_accuracy: 0.5812\n",
      "Epoch 188/200\n",
      "1407/1407 [==============================] - 11s 8ms/step - loss: 0.8280 - accuracy: 0.7155 - val_loss: 1.1909 - val_accuracy: 0.5890\n",
      "Epoch 189/200\n",
      "1407/1407 [==============================] - 10s 7ms/step - loss: 0.8260 - accuracy: 0.7149 - val_loss: 1.2127 - val_accuracy: 0.5918\n",
      "Epoch 190/200\n",
      "1407/1407 [==============================] - 11s 8ms/step - loss: 0.8240 - accuracy: 0.7183 - val_loss: 1.2065 - val_accuracy: 0.5914\n",
      "Epoch 191/200\n",
      "1407/1407 [==============================] - 10s 7ms/step - loss: 0.8464 - accuracy: 0.7129 - val_loss: 1.1919 - val_accuracy: 0.5930\n",
      "Epoch 192/200\n",
      "1407/1407 [==============================] - 10s 7ms/step - loss: 0.8179 - accuracy: 0.7200 - val_loss: 1.2018 - val_accuracy: 0.5926\n",
      "Epoch 193/200\n",
      "1407/1407 [==============================] - 11s 8ms/step - loss: 0.8141 - accuracy: 0.7203 - val_loss: 1.2423 - val_accuracy: 0.5864\n",
      "Epoch 194/200\n",
      "1407/1407 [==============================] - 16s 12ms/step - loss: 0.8067 - accuracy: 0.7226 - val_loss: 1.2122 - val_accuracy: 0.5928\n",
      "Epoch 195/200\n",
      "1407/1407 [==============================] - 12s 8ms/step - loss: 0.8230 - accuracy: 0.7174 - val_loss: 1.2276 - val_accuracy: 0.5848\n",
      "Epoch 196/200\n",
      "1407/1407 [==============================] - 18s 13ms/step - loss: 0.8121 - accuracy: 0.7248 - val_loss: 1.2202 - val_accuracy: 0.5878\n",
      "Epoch 197/200\n",
      "1407/1407 [==============================] - 14s 10ms/step - loss: 0.8175 - accuracy: 0.7196 - val_loss: 1.2103 - val_accuracy: 0.5880\n",
      "Epoch 198/200\n",
      "1407/1407 [==============================] - 12s 9ms/step - loss: 0.8172 - accuracy: 0.7174 - val_loss: 1.2057 - val_accuracy: 0.5966\n",
      "Epoch 199/200\n",
      "1407/1407 [==============================] - 12s 8ms/step - loss: 0.8140 - accuracy: 0.7202 - val_loss: 1.1928 - val_accuracy: 0.5960\n",
      "Epoch 200/200\n",
      "1407/1407 [==============================] - 14s 10ms/step - loss: 0.8132 - accuracy: 0.7201 - val_loss: 1.2098 - val_accuracy: 0.5920\n",
      "313/313 [==============================] - 1s 3ms/step - loss: 499.3412 - accuracy: 0.2282\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[499.34124755859375, 0.2282000035047531]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "batch_size = 32 \n",
    "num_epochs = 200 \n",
    "kernel_size = 3 # мы будем использовать ядра 3x3 повсюду\n",
    "pool_size = 2 # мы будем использовать объединение 2х2 повсюду\n",
    "conv_depth_1 = 64 # первоначально у нас будет 32 ядра на слой преобразования\n",
    "conv_depth_2 = 128 # переключение на 64 после первого уровня объединения\n",
    "drop_prob_1 = 0.25 # выбывает после объединения с вероятностью 0,25\n",
    "drop_prob_2 = 0.5 # выпадают в плотном слое с вероятностью 0,5\n",
    "hidden_size = 512 # в плотном слое будет 512 нейронов\n",
    "\n",
    "(X_train, y_train), (X_test, y_test) = cifar10.load_data() # извлечение данных CIFAR-10\n",
    "num_train, depth, height, width = X_train.shape # в CIFAR-10 содержится 50000 обучающих примеров\n",
    "num_test = X_test.shape[0] # в CIFAR-10 содержится 10000 тестовых примеров\n",
    "num_classes = np.unique(y_train).shape[0] # существует 10 классов изображений\n",
    "X_train = X_train.astype('float32')\n",
    "X_test = X_test.astype('float32')\n",
    "X_train /= np.max(X_train) # Нормализуйте данные до диапазона [0, 1]\n",
    "X_test /= np.max(X_train) # Нормализуйте данные до диапазона [0, 1]\n",
    "\n",
    "Y_train = np_utils.to_categorical(y_train, num_classes) # кодирование тренировачных данных\n",
    "Y_test = np_utils.to_categorical(y_test, num_classes) # кодирование тестировочных данных\n",
    "\n",
    "\n",
    "inp = Input(shape=(depth, height, width)) # N.B. глубина занимает первое место в Керасе\n",
    "# Conv [32] -> Conv [32] -> Pool (with dropout on the pooling layer)\n",
    "conv_1 = Convolution2D(conv_depth_1, kernel_size, kernel_size,\n",
    "padding='same', activation='relu')(inp) #устарело\n",
    "conv_2 = Convolution2D(conv_depth_1, kernel_size, kernel_size,\n",
    "padding='same', activation='relu')(conv_1)\n",
    "pool_1 = MaxPooling2D(pool_size=(pool_size, pool_size))(conv_2)\n",
    "drop_1 = Dropout(drop_prob_1)(pool_1)\n",
    "# Conv [64] -> Conv [64] -> Pool (with dropout on the pooling layer)\n",
    "conv_3 = Convolution2D(conv_depth_2, kernel_size, kernel_size,\n",
    "padding='same', activation='relu')(drop_1)\n",
    "conv_4 = Convolution2D(conv_depth_2, kernel_size, kernel_size,\n",
    "padding='same', activation='relu')(conv_3)\n",
    "pool_2 = MaxPooling2D(pool_size=(pool_size, pool_size),padding='same')(conv_4) # padding='same' входное изображение должно иметь нулевое заполнение, чтобы вывод в свертке не отличался по размеру от ввода. \n",
    "drop_2 = Dropout(drop_prob_1)(pool_2)\n",
    "#Теперь выровняйте до 1D, примените Плотный -> ReLU (с выпадением) -> softmax\n",
    "flat = Flatten()(drop_2)\n",
    "hidden = Dense(hidden_size, activation='relu')(flat)\n",
    "\n",
    "drop_3 = Dropout(drop_prob_2)(hidden)\n",
    "out = Dense(num_classes, activation='softmax')(drop_3)\n",
    "model = Model(inputs=inp, outputs=out) # Чтобы определить модель, просто укажите ее входные и выходные слои\n",
    "model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy']) \n",
    "model.fit(X_train, Y_train, batch_size=batch_size, epochs=num_epochs, verbose=1, validation_split=0.1) # \n",
    "model.evaluate(X_test, Y_test, verbose=1) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a76cda5b",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/200\n",
      "1407/1407 [==============================] - 11s 8ms/step - loss: 1.7983 - accuracy: 0.3281 - val_loss: 1.5034 - val_accuracy: 0.4390\n",
      "Epoch 2/200\n",
      "1407/1407 [==============================] - 9s 7ms/step - loss: 1.5417 - accuracy: 0.4312 - val_loss: 1.3625 - val_accuracy: 0.5004\n",
      "Epoch 3/200\n",
      "1407/1407 [==============================] - 8s 6ms/step - loss: 1.4616 - accuracy: 0.4657 - val_loss: 1.2962 - val_accuracy: 0.5314\n",
      "Epoch 4/200\n",
      "1407/1407 [==============================] - 8s 6ms/step - loss: 1.4109 - accuracy: 0.4841 - val_loss: 1.2573 - val_accuracy: 0.5448\n",
      "Epoch 5/200\n",
      "1407/1407 [==============================] - 11s 8ms/step - loss: 1.3654 - accuracy: 0.5087 - val_loss: 1.2059 - val_accuracy: 0.5654\n",
      "Epoch 6/200\n",
      "1407/1407 [==============================] - 8s 6ms/step - loss: 1.3366 - accuracy: 0.5202 - val_loss: 1.1655 - val_accuracy: 0.5904\n",
      "Epoch 7/200\n",
      "1407/1407 [==============================] - 9s 7ms/step - loss: 1.3042 - accuracy: 0.5300 - val_loss: 1.1854 - val_accuracy: 0.5696\n",
      "Epoch 8/200\n",
      "1407/1407 [==============================] - 9s 6ms/step - loss: 1.2865 - accuracy: 0.5417 - val_loss: 1.1335 - val_accuracy: 0.5952\n",
      "Epoch 9/200\n",
      "1407/1407 [==============================] - 8s 6ms/step - loss: 1.2676 - accuracy: 0.5439 - val_loss: 1.1076 - val_accuracy: 0.6112\n",
      "Epoch 10/200\n",
      "1407/1407 [==============================] - 8s 6ms/step - loss: 1.2466 - accuracy: 0.5551 - val_loss: 1.1031 - val_accuracy: 0.6116\n",
      "Epoch 11/200\n",
      "1407/1407 [==============================] - 9s 6ms/step - loss: 1.2347 - accuracy: 0.5566 - val_loss: 1.1557 - val_accuracy: 0.5878\n",
      "Epoch 12/200\n",
      "1407/1407 [==============================] - 8s 6ms/step - loss: 1.2230 - accuracy: 0.5640 - val_loss: 1.1010 - val_accuracy: 0.6124\n",
      "Epoch 13/200\n",
      "1407/1407 [==============================] - 8s 6ms/step - loss: 1.2031 - accuracy: 0.5716 - val_loss: 1.0951 - val_accuracy: 0.6176\n",
      "Epoch 14/200\n",
      "1407/1407 [==============================] - 8s 6ms/step - loss: 1.2004 - accuracy: 0.5711 - val_loss: 1.0931 - val_accuracy: 0.6146\n",
      "Epoch 15/200\n",
      "1407/1407 [==============================] - 8s 6ms/step - loss: 1.1909 - accuracy: 0.5773 - val_loss: 1.0885 - val_accuracy: 0.6174\n",
      "Epoch 16/200\n",
      "1407/1407 [==============================] - 8s 6ms/step - loss: 1.1790 - accuracy: 0.5818 - val_loss: 1.0659 - val_accuracy: 0.6294\n",
      "Epoch 17/200\n",
      "1407/1407 [==============================] - 8s 6ms/step - loss: 1.1718 - accuracy: 0.5864 - val_loss: 1.0730 - val_accuracy: 0.6292\n",
      "Epoch 18/200\n",
      "1407/1407 [==============================] - 8s 6ms/step - loss: 1.1623 - accuracy: 0.5880 - val_loss: 1.0610 - val_accuracy: 0.6326\n",
      "Epoch 19/200\n",
      "1407/1407 [==============================] - 8s 6ms/step - loss: 1.1577 - accuracy: 0.5898 - val_loss: 1.0541 - val_accuracy: 0.6360\n",
      "Epoch 20/200\n",
      "1407/1407 [==============================] - 9s 6ms/step - loss: 1.1502 - accuracy: 0.5908 - val_loss: 1.0735 - val_accuracy: 0.6308\n",
      "Epoch 21/200\n",
      "1407/1407 [==============================] - 8s 6ms/step - loss: 1.1410 - accuracy: 0.5933 - val_loss: 1.0373 - val_accuracy: 0.6422\n",
      "Epoch 22/200\n",
      "1407/1407 [==============================] - 8s 6ms/step - loss: 1.1343 - accuracy: 0.5949 - val_loss: 1.0607 - val_accuracy: 0.6288\n",
      "Epoch 23/200\n",
      "1407/1407 [==============================] - 8s 6ms/step - loss: 1.1387 - accuracy: 0.5956 - val_loss: 1.0614 - val_accuracy: 0.6324\n",
      "Epoch 24/200\n",
      "1407/1407 [==============================] - 8s 6ms/step - loss: 1.1305 - accuracy: 0.6013 - val_loss: 1.0570 - val_accuracy: 0.6274\n",
      "Epoch 25/200\n",
      "1407/1407 [==============================] - 8s 6ms/step - loss: 1.1260 - accuracy: 0.5978 - val_loss: 1.0370 - val_accuracy: 0.6406\n",
      "Epoch 26/200\n",
      "1407/1407 [==============================] - 8s 6ms/step - loss: 1.1192 - accuracy: 0.6027 - val_loss: 1.0455 - val_accuracy: 0.6366\n",
      "Epoch 27/200\n",
      "1407/1407 [==============================] - 12s 9ms/step - loss: 1.1182 - accuracy: 0.6064 - val_loss: 1.0376 - val_accuracy: 0.6366\n",
      "Epoch 28/200\n",
      "1407/1407 [==============================] - 9s 6ms/step - loss: 1.1056 - accuracy: 0.6073 - val_loss: 1.0234 - val_accuracy: 0.6414\n",
      "Epoch 29/200\n",
      "1407/1407 [==============================] - 10s 7ms/step - loss: 1.1044 - accuracy: 0.6104 - val_loss: 1.0418 - val_accuracy: 0.6364\n",
      "Epoch 30/200\n",
      "1407/1407 [==============================] - 8s 6ms/step - loss: 1.1043 - accuracy: 0.6083 - val_loss: 1.0326 - val_accuracy: 0.6354\n",
      "Epoch 31/200\n",
      "1407/1407 [==============================] - 8s 6ms/step - loss: 1.0916 - accuracy: 0.6116 - val_loss: 1.0270 - val_accuracy: 0.6376\n",
      "Epoch 32/200\n",
      "1407/1407 [==============================] - 8s 6ms/step - loss: 1.0974 - accuracy: 0.6118 - val_loss: 1.0167 - val_accuracy: 0.6474\n",
      "Epoch 33/200\n",
      "1407/1407 [==============================] - 9s 7ms/step - loss: 1.0921 - accuracy: 0.6145 - val_loss: 1.0214 - val_accuracy: 0.6470\n",
      "Epoch 34/200\n",
      "1407/1407 [==============================] - 12s 9ms/step - loss: 1.0879 - accuracy: 0.6142 - val_loss: 1.0285 - val_accuracy: 0.6444\n",
      "Epoch 35/200\n",
      "1407/1407 [==============================] - 14s 10ms/step - loss: 1.0886 - accuracy: 0.6156 - val_loss: 1.0083 - val_accuracy: 0.6500\n",
      "Epoch 36/200\n",
      "1407/1407 [==============================] - 12s 9ms/step - loss: 1.0854 - accuracy: 0.6139 - val_loss: 1.0227 - val_accuracy: 0.6464\n",
      "Epoch 37/200\n",
      "1407/1407 [==============================] - 9s 7ms/step - loss: 1.0794 - accuracy: 0.6173 - val_loss: 1.0205 - val_accuracy: 0.6504\n",
      "Epoch 38/200\n",
      "1407/1407 [==============================] - 10s 7ms/step - loss: 1.0740 - accuracy: 0.6192 - val_loss: 1.0301 - val_accuracy: 0.6438\n",
      "Epoch 39/200\n",
      "1407/1407 [==============================] - 9s 6ms/step - loss: 1.0745 - accuracy: 0.6193 - val_loss: 1.0221 - val_accuracy: 0.6444\n",
      "Epoch 40/200\n",
      "1407/1407 [==============================] - 9s 6ms/step - loss: 1.0741 - accuracy: 0.6216 - val_loss: 1.0085 - val_accuracy: 0.6484\n",
      "Epoch 41/200\n",
      "1407/1407 [==============================] - 9s 6ms/step - loss: 1.0721 - accuracy: 0.6226 - val_loss: 0.9972 - val_accuracy: 0.6544\n",
      "Epoch 42/200\n",
      "1407/1407 [==============================] - 8s 6ms/step - loss: 1.0686 - accuracy: 0.6215 - val_loss: 1.0377 - val_accuracy: 0.6324\n",
      "Epoch 43/200\n",
      "1407/1407 [==============================] - 8s 6ms/step - loss: 1.0668 - accuracy: 0.6236 - val_loss: 1.0064 - val_accuracy: 0.6516\n",
      "Epoch 44/200\n",
      "1407/1407 [==============================] - 9s 6ms/step - loss: 1.0666 - accuracy: 0.6236 - val_loss: 1.0244 - val_accuracy: 0.6442\n",
      "Epoch 45/200\n",
      "1407/1407 [==============================] - 8s 6ms/step - loss: 1.0647 - accuracy: 0.6242 - val_loss: 1.0310 - val_accuracy: 0.6466\n",
      "Epoch 46/200\n",
      "1407/1407 [==============================] - 8s 6ms/step - loss: 1.0529 - accuracy: 0.6292 - val_loss: 1.0072 - val_accuracy: 0.6490\n",
      "Epoch 47/200\n",
      "1407/1407 [==============================] - 10s 7ms/step - loss: 1.0491 - accuracy: 0.6303 - val_loss: 1.0480 - val_accuracy: 0.6330\n",
      "Epoch 48/200\n",
      "1407/1407 [==============================] - 9s 6ms/step - loss: 1.0542 - accuracy: 0.6264 - val_loss: 1.0194 - val_accuracy: 0.6540\n",
      "Epoch 49/200\n",
      "1407/1407 [==============================] - 8s 6ms/step - loss: 1.0534 - accuracy: 0.6285 - val_loss: 1.0307 - val_accuracy: 0.6360\n",
      "Epoch 50/200\n",
      "1407/1407 [==============================] - 8s 6ms/step - loss: 1.0553 - accuracy: 0.6278 - val_loss: 1.0065 - val_accuracy: 0.6568\n",
      "Epoch 51/200\n",
      "1407/1407 [==============================] - 9s 6ms/step - loss: 1.0452 - accuracy: 0.6322 - val_loss: 0.9942 - val_accuracy: 0.6558\n",
      "Epoch 52/200\n",
      "1407/1407 [==============================] - 9s 6ms/step - loss: 1.0457 - accuracy: 0.6313 - val_loss: 1.0024 - val_accuracy: 0.6526\n",
      "Epoch 53/200\n",
      "1407/1407 [==============================] - 8s 6ms/step - loss: 1.0465 - accuracy: 0.6323 - val_loss: 1.0191 - val_accuracy: 0.6412\n",
      "Epoch 54/200\n",
      "1407/1407 [==============================] - 8s 6ms/step - loss: 1.0454 - accuracy: 0.6324 - val_loss: 1.0236 - val_accuracy: 0.6508\n",
      "Epoch 55/200\n",
      "1407/1407 [==============================] - 9s 6ms/step - loss: 1.0447 - accuracy: 0.6327 - val_loss: 0.9993 - val_accuracy: 0.6546\n",
      "Epoch 56/200\n",
      "1407/1407 [==============================] - 9s 6ms/step - loss: 1.0397 - accuracy: 0.6328 - val_loss: 1.0133 - val_accuracy: 0.6482\n",
      "Epoch 57/200\n",
      "1407/1407 [==============================] - 10s 7ms/step - loss: 1.0391 - accuracy: 0.6331 - val_loss: 1.0058 - val_accuracy: 0.6496\n",
      "Epoch 58/200\n",
      "1407/1407 [==============================] - 12s 9ms/step - loss: 1.0331 - accuracy: 0.6334 - val_loss: 0.9932 - val_accuracy: 0.6542\n",
      "Epoch 59/200\n",
      "1407/1407 [==============================] - 11s 8ms/step - loss: 1.0375 - accuracy: 0.6351 - val_loss: 0.9832 - val_accuracy: 0.6560\n",
      "Epoch 60/200\n",
      "1407/1407 [==============================] - 10s 7ms/step - loss: 1.0349 - accuracy: 0.6332 - val_loss: 0.9896 - val_accuracy: 0.6610\n",
      "Epoch 61/200\n",
      "1407/1407 [==============================] - 8s 6ms/step - loss: 1.0305 - accuracy: 0.6376 - val_loss: 0.9828 - val_accuracy: 0.6586\n",
      "Epoch 62/200\n",
      "1407/1407 [==============================] - 12s 9ms/step - loss: 1.0281 - accuracy: 0.6369 - val_loss: 0.9891 - val_accuracy: 0.6544\n",
      "Epoch 63/200\n",
      "1407/1407 [==============================] - 9s 6ms/step - loss: 1.0344 - accuracy: 0.6354 - val_loss: 0.9938 - val_accuracy: 0.6554\n",
      "Epoch 64/200\n",
      "1407/1407 [==============================] - 11s 8ms/step - loss: 1.0262 - accuracy: 0.6357 - val_loss: 0.9870 - val_accuracy: 0.6546\n",
      "Epoch 65/200\n",
      "1407/1407 [==============================] - 9s 6ms/step - loss: 1.0266 - accuracy: 0.6379 - val_loss: 0.9962 - val_accuracy: 0.6516\n",
      "Epoch 66/200\n",
      "1407/1407 [==============================] - 10s 7ms/step - loss: 1.0242 - accuracy: 0.6415 - val_loss: 0.9989 - val_accuracy: 0.6504\n",
      "Epoch 67/200\n",
      "1407/1407 [==============================] - 8s 6ms/step - loss: 1.0297 - accuracy: 0.6359 - val_loss: 0.9970 - val_accuracy: 0.6524\n",
      "Epoch 68/200\n",
      "1407/1407 [==============================] - 9s 6ms/step - loss: 1.0199 - accuracy: 0.6399 - val_loss: 0.9746 - val_accuracy: 0.6518\n",
      "Epoch 69/200\n",
      "1407/1407 [==============================] - 9s 6ms/step - loss: 1.0186 - accuracy: 0.6408 - val_loss: 0.9828 - val_accuracy: 0.6614\n",
      "Epoch 70/200\n",
      "1407/1407 [==============================] - 8s 6ms/step - loss: 1.0211 - accuracy: 0.6400 - val_loss: 0.9926 - val_accuracy: 0.6578\n",
      "Epoch 71/200\n",
      "1407/1407 [==============================] - 10s 7ms/step - loss: 1.0209 - accuracy: 0.6406 - val_loss: 0.9731 - val_accuracy: 0.6582\n",
      "Epoch 72/200\n",
      "1407/1407 [==============================] - 10s 7ms/step - loss: 1.0184 - accuracy: 0.6414 - val_loss: 0.9978 - val_accuracy: 0.6518\n",
      "Epoch 73/200\n",
      "1407/1407 [==============================] - 9s 7ms/step - loss: 1.0155 - accuracy: 0.6422 - val_loss: 0.9847 - val_accuracy: 0.6604\n",
      "Epoch 74/200\n",
      "1407/1407 [==============================] - 9s 6ms/step - loss: 1.0168 - accuracy: 0.6400 - val_loss: 0.9832 - val_accuracy: 0.6578\n",
      "Epoch 75/200\n",
      "1407/1407 [==============================] - 11s 8ms/step - loss: 1.0162 - accuracy: 0.6420 - val_loss: 0.9838 - val_accuracy: 0.6592\n",
      "Epoch 76/200\n",
      "1407/1407 [==============================] - 10s 7ms/step - loss: 1.0175 - accuracy: 0.6464 - val_loss: 0.9789 - val_accuracy: 0.6542\n",
      "Epoch 77/200\n",
      "1407/1407 [==============================] - 8s 6ms/step - loss: 1.0121 - accuracy: 0.6426 - val_loss: 0.9647 - val_accuracy: 0.6668\n",
      "Epoch 78/200\n",
      "1407/1407 [==============================] - 10s 7ms/step - loss: 1.0123 - accuracy: 0.6439 - val_loss: 0.9714 - val_accuracy: 0.6646\n",
      "Epoch 79/200\n",
      "1407/1407 [==============================] - 9s 7ms/step - loss: 1.0125 - accuracy: 0.6462 - val_loss: 0.9736 - val_accuracy: 0.6562\n",
      "Epoch 80/200\n",
      "1407/1407 [==============================] - 9s 6ms/step - loss: 1.0111 - accuracy: 0.6431 - val_loss: 0.9918 - val_accuracy: 0.6534\n",
      "Epoch 81/200\n",
      "1407/1407 [==============================] - 8s 6ms/step - loss: 1.0090 - accuracy: 0.6460 - val_loss: 0.9734 - val_accuracy: 0.6642\n",
      "Epoch 82/200\n",
      "1407/1407 [==============================] - 8s 6ms/step - loss: 1.0102 - accuracy: 0.6416 - val_loss: 0.9991 - val_accuracy: 0.6582\n",
      "Epoch 83/200\n",
      "1407/1407 [==============================] - 9s 6ms/step - loss: 1.0063 - accuracy: 0.6483 - val_loss: 0.9794 - val_accuracy: 0.6604\n",
      "Epoch 84/200\n",
      "1407/1407 [==============================] - 9s 6ms/step - loss: 1.0111 - accuracy: 0.6450 - val_loss: 0.9857 - val_accuracy: 0.6594\n",
      "Epoch 85/200\n",
      "1407/1407 [==============================] - 9s 7ms/step - loss: 1.0095 - accuracy: 0.6423 - val_loss: 0.9926 - val_accuracy: 0.6534\n",
      "Epoch 86/200\n",
      "1407/1407 [==============================] - 9s 6ms/step - loss: 1.0061 - accuracy: 0.6448 - val_loss: 0.9737 - val_accuracy: 0.6632\n",
      "Epoch 87/200\n",
      "1407/1407 [==============================] - 12s 9ms/step - loss: 1.0045 - accuracy: 0.6487 - val_loss: 0.9836 - val_accuracy: 0.6582\n",
      "Epoch 88/200\n",
      "1407/1407 [==============================] - 11s 8ms/step - loss: 1.0035 - accuracy: 0.6482 - val_loss: 0.9692 - val_accuracy: 0.6634\n",
      "Epoch 89/200\n",
      "1407/1407 [==============================] - 12s 8ms/step - loss: 1.0026 - accuracy: 0.6460 - val_loss: 0.9742 - val_accuracy: 0.6660\n",
      "Epoch 90/200\n",
      "1407/1407 [==============================] - 9s 6ms/step - loss: 1.0052 - accuracy: 0.6447 - val_loss: 0.9938 - val_accuracy: 0.6638\n",
      "Epoch 91/200\n",
      "1407/1407 [==============================] - 9s 6ms/step - loss: 0.9999 - accuracy: 0.6503 - val_loss: 0.9960 - val_accuracy: 0.6524\n",
      "Epoch 92/200\n",
      "1407/1407 [==============================] - 10s 7ms/step - loss: 1.0003 - accuracy: 0.6474 - val_loss: 0.9736 - val_accuracy: 0.6640\n",
      "Epoch 93/200\n",
      "1407/1407 [==============================] - 12s 9ms/step - loss: 1.0018 - accuracy: 0.6494 - val_loss: 0.9786 - val_accuracy: 0.6656\n",
      "Epoch 94/200\n",
      "1407/1407 [==============================] - 11s 8ms/step - loss: 1.0061 - accuracy: 0.6469 - val_loss: 0.9674 - val_accuracy: 0.6688\n",
      "Epoch 95/200\n",
      "1407/1407 [==============================] - 11s 8ms/step - loss: 0.9996 - accuracy: 0.6472 - val_loss: 0.9630 - val_accuracy: 0.6640\n",
      "Epoch 96/200\n",
      "1407/1407 [==============================] - 10s 7ms/step - loss: 1.0012 - accuracy: 0.6459 - val_loss: 0.9760 - val_accuracy: 0.6648\n",
      "Epoch 97/200\n",
      "1407/1407 [==============================] - 14s 10ms/step - loss: 0.9999 - accuracy: 0.6470 - val_loss: 0.9965 - val_accuracy: 0.6510\n",
      "Epoch 98/200\n",
      "1407/1407 [==============================] - 14s 10ms/step - loss: 0.9980 - accuracy: 0.6511 - val_loss: 0.9744 - val_accuracy: 0.6600\n",
      "Epoch 99/200\n",
      "1407/1407 [==============================] - 23s 16ms/step - loss: 0.9974 - accuracy: 0.6484 - val_loss: 0.9859 - val_accuracy: 0.6540\n",
      "Epoch 100/200\n",
      "1407/1407 [==============================] - 13s 9ms/step - loss: 0.9995 - accuracy: 0.6519 - val_loss: 0.9691 - val_accuracy: 0.6650\n",
      "Epoch 101/200\n",
      "1407/1407 [==============================] - 11s 8ms/step - loss: 0.9969 - accuracy: 0.6492 - val_loss: 0.9853 - val_accuracy: 0.6592\n",
      "Epoch 102/200\n",
      "1407/1407 [==============================] - 10s 7ms/step - loss: 0.9977 - accuracy: 0.6502 - val_loss: 0.9833 - val_accuracy: 0.6644\n",
      "Epoch 103/200\n",
      "1407/1407 [==============================] - 11s 8ms/step - loss: 0.9985 - accuracy: 0.6482 - val_loss: 0.9618 - val_accuracy: 0.6620\n",
      "Epoch 104/200\n",
      "1407/1407 [==============================] - 11s 8ms/step - loss: 0.9828 - accuracy: 0.6560 - val_loss: 0.9857 - val_accuracy: 0.6602\n",
      "Epoch 105/200\n",
      "1407/1407 [==============================] - 11s 8ms/step - loss: 0.9914 - accuracy: 0.6522 - val_loss: 0.9674 - val_accuracy: 0.6690\n",
      "Epoch 106/200\n",
      "1407/1407 [==============================] - 11s 8ms/step - loss: 0.9980 - accuracy: 0.6496 - val_loss: 0.9721 - val_accuracy: 0.6614\n",
      "Epoch 107/200\n",
      "1407/1407 [==============================] - 11s 8ms/step - loss: 0.9916 - accuracy: 0.6491 - val_loss: 0.9660 - val_accuracy: 0.6634\n",
      "Epoch 108/200\n",
      "1407/1407 [==============================] - 10s 7ms/step - loss: 0.9879 - accuracy: 0.6536 - val_loss: 0.9596 - val_accuracy: 0.6728\n",
      "Epoch 109/200\n",
      "1407/1407 [==============================] - 10s 7ms/step - loss: 0.9863 - accuracy: 0.6513 - val_loss: 0.9729 - val_accuracy: 0.6698\n",
      "Epoch 110/200\n",
      "1407/1407 [==============================] - 10s 7ms/step - loss: 0.9873 - accuracy: 0.6523 - val_loss: 0.9655 - val_accuracy: 0.6656\n",
      "Epoch 111/200\n",
      "1407/1407 [==============================] - 11s 7ms/step - loss: 0.9874 - accuracy: 0.6536 - val_loss: 0.9797 - val_accuracy: 0.6638\n",
      "Epoch 112/200\n",
      "1407/1407 [==============================] - 10s 7ms/step - loss: 0.9926 - accuracy: 0.6511 - val_loss: 0.9674 - val_accuracy: 0.6626\n",
      "Epoch 113/200\n",
      "1407/1407 [==============================] - 11s 8ms/step - loss: 0.9861 - accuracy: 0.6535 - val_loss: 0.9734 - val_accuracy: 0.6554\n",
      "Epoch 114/200\n",
      "1407/1407 [==============================] - 11s 8ms/step - loss: 0.9832 - accuracy: 0.6545 - val_loss: 0.9713 - val_accuracy: 0.6656\n",
      "Epoch 115/200\n",
      "1407/1407 [==============================] - 10s 7ms/step - loss: 0.9876 - accuracy: 0.6524 - val_loss: 0.9676 - val_accuracy: 0.6640\n",
      "Epoch 116/200\n",
      "1407/1407 [==============================] - 10s 7ms/step - loss: 0.9810 - accuracy: 0.6530 - val_loss: 0.9950 - val_accuracy: 0.6548\n",
      "Epoch 117/200\n",
      "1407/1407 [==============================] - 12s 8ms/step - loss: 0.9852 - accuracy: 0.6529 - val_loss: 0.9951 - val_accuracy: 0.6538\n",
      "Epoch 118/200\n",
      "1407/1407 [==============================] - 11s 8ms/step - loss: 0.9837 - accuracy: 0.6546 - val_loss: 0.9642 - val_accuracy: 0.6658\n",
      "Epoch 119/200\n",
      "1407/1407 [==============================] - 10s 7ms/step - loss: 0.9833 - accuracy: 0.6534 - val_loss: 0.9772 - val_accuracy: 0.6648\n",
      "Epoch 120/200\n",
      "1407/1407 [==============================] - 10s 7ms/step - loss: 0.9826 - accuracy: 0.6525 - val_loss: 0.9718 - val_accuracy: 0.6664\n",
      "Epoch 121/200\n",
      "1407/1407 [==============================] - 10s 7ms/step - loss: 0.9825 - accuracy: 0.6545 - val_loss: 1.0009 - val_accuracy: 0.6542\n",
      "Epoch 122/200\n",
      "1407/1407 [==============================] - 10s 7ms/step - loss: 0.9803 - accuracy: 0.6565 - val_loss: 0.9601 - val_accuracy: 0.6684\n",
      "Epoch 123/200\n",
      "1407/1407 [==============================] - 12s 8ms/step - loss: 0.9839 - accuracy: 0.6548 - val_loss: 0.9778 - val_accuracy: 0.6564\n",
      "Epoch 124/200\n",
      "1407/1407 [==============================] - 11s 8ms/step - loss: 0.9875 - accuracy: 0.6534 - val_loss: 0.9869 - val_accuracy: 0.6492\n",
      "Epoch 125/200\n",
      "1407/1407 [==============================] - 10s 7ms/step - loss: 0.9801 - accuracy: 0.6567 - val_loss: 0.9555 - val_accuracy: 0.6712\n",
      "Epoch 126/200\n",
      "1407/1407 [==============================] - 11s 8ms/step - loss: 0.9793 - accuracy: 0.6572 - val_loss: 0.9544 - val_accuracy: 0.6728\n",
      "Epoch 127/200\n",
      "1407/1407 [==============================] - 11s 7ms/step - loss: 0.9809 - accuracy: 0.6563 - val_loss: 0.9734 - val_accuracy: 0.6606\n",
      "Epoch 128/200\n",
      "1407/1407 [==============================] - 10s 7ms/step - loss: 0.9775 - accuracy: 0.6575 - val_loss: 0.9548 - val_accuracy: 0.6714\n",
      "Epoch 129/200\n",
      "1407/1407 [==============================] - 10s 7ms/step - loss: 0.9858 - accuracy: 0.6549 - val_loss: 0.9594 - val_accuracy: 0.6666\n",
      "Epoch 130/200\n",
      "1407/1407 [==============================] - 11s 8ms/step - loss: 0.9795 - accuracy: 0.6565 - val_loss: 0.9733 - val_accuracy: 0.6654\n",
      "Epoch 131/200\n",
      "1407/1407 [==============================] - 12s 8ms/step - loss: 0.9844 - accuracy: 0.6559 - val_loss: 0.9546 - val_accuracy: 0.6686\n",
      "Epoch 132/200\n",
      "1407/1407 [==============================] - 10s 7ms/step - loss: 0.9871 - accuracy: 0.6560 - val_loss: 0.9631 - val_accuracy: 0.6678\n",
      "Epoch 133/200\n",
      "1407/1407 [==============================] - 10s 7ms/step - loss: 0.9790 - accuracy: 0.6556 - val_loss: 0.9479 - val_accuracy: 0.6762\n",
      "Epoch 134/200\n",
      "1407/1407 [==============================] - 11s 8ms/step - loss: 0.9764 - accuracy: 0.6554 - val_loss: 0.9604 - val_accuracy: 0.6744\n",
      "Epoch 135/200\n",
      "1407/1407 [==============================] - 10s 7ms/step - loss: 0.9844 - accuracy: 0.6549 - val_loss: 0.9631 - val_accuracy: 0.6684\n",
      "Epoch 136/200\n",
      "1407/1407 [==============================] - 13s 9ms/step - loss: 0.9730 - accuracy: 0.6560 - val_loss: 0.9632 - val_accuracy: 0.6644\n",
      "Epoch 137/200\n",
      "1407/1407 [==============================] - 11s 8ms/step - loss: 0.9785 - accuracy: 0.6582 - val_loss: 1.0000 - val_accuracy: 0.6614\n",
      "Epoch 138/200\n",
      "1407/1407 [==============================] - 12s 8ms/step - loss: 0.9757 - accuracy: 0.6577 - val_loss: 0.9597 - val_accuracy: 0.6660\n",
      "Epoch 139/200\n",
      "1407/1407 [==============================] - 12s 9ms/step - loss: 0.9814 - accuracy: 0.6561 - val_loss: 0.9553 - val_accuracy: 0.6690\n",
      "Epoch 140/200\n",
      "1407/1407 [==============================] - 11s 8ms/step - loss: 0.9735 - accuracy: 0.6570 - val_loss: 0.9678 - val_accuracy: 0.6776\n",
      "Epoch 141/200\n",
      "1407/1407 [==============================] - 11s 8ms/step - loss: 0.9769 - accuracy: 0.6577 - val_loss: 0.9602 - val_accuracy: 0.6560\n",
      "Epoch 142/200\n",
      "1407/1407 [==============================] - 10s 7ms/step - loss: 0.9743 - accuracy: 0.6576 - val_loss: 0.9697 - val_accuracy: 0.6650\n",
      "Epoch 143/200\n",
      "1407/1407 [==============================] - 10s 7ms/step - loss: 0.9741 - accuracy: 0.6550 - val_loss: 0.9733 - val_accuracy: 0.6704\n",
      "Epoch 144/200\n",
      "1407/1407 [==============================] - 11s 8ms/step - loss: 0.9752 - accuracy: 0.6581 - val_loss: 0.9421 - val_accuracy: 0.6786\n",
      "Epoch 145/200\n",
      "1407/1407 [==============================] - 10s 7ms/step - loss: 0.9749 - accuracy: 0.6592 - val_loss: 0.9724 - val_accuracy: 0.6696\n",
      "Epoch 146/200\n",
      "1407/1407 [==============================] - 10s 7ms/step - loss: 0.9756 - accuracy: 0.6591 - val_loss: 0.9483 - val_accuracy: 0.6768\n",
      "Epoch 147/200\n",
      "1407/1407 [==============================] - 9s 7ms/step - loss: 0.9718 - accuracy: 0.6584 - val_loss: 0.9799 - val_accuracy: 0.6626\n",
      "Epoch 148/200\n",
      "1407/1407 [==============================] - 10s 7ms/step - loss: 0.9733 - accuracy: 0.6586 - val_loss: 0.9662 - val_accuracy: 0.6678\n",
      "Epoch 149/200\n",
      "1407/1407 [==============================] - 19s 13ms/step - loss: 0.9763 - accuracy: 0.6578 - val_loss: 0.9540 - val_accuracy: 0.6730\n",
      "Epoch 150/200\n",
      "1407/1407 [==============================] - 12s 9ms/step - loss: 0.9698 - accuracy: 0.6613 - val_loss: 0.9541 - val_accuracy: 0.6666\n",
      "Epoch 151/200\n",
      "1407/1407 [==============================] - 9s 6ms/step - loss: 0.9731 - accuracy: 0.6578 - val_loss: 0.9510 - val_accuracy: 0.6734\n",
      "Epoch 152/200\n",
      "1407/1407 [==============================] - 11s 8ms/step - loss: 0.9758 - accuracy: 0.6597 - val_loss: 0.9568 - val_accuracy: 0.6764\n",
      "Epoch 153/200\n",
      "1407/1407 [==============================] - 11s 8ms/step - loss: 0.9776 - accuracy: 0.6578 - val_loss: 0.9690 - val_accuracy: 0.6684\n",
      "Epoch 154/200\n",
      "1407/1407 [==============================] - 10s 7ms/step - loss: 0.9700 - accuracy: 0.6603 - val_loss: 0.9553 - val_accuracy: 0.6730\n",
      "Epoch 155/200\n",
      "1407/1407 [==============================] - 10s 7ms/step - loss: 0.9761 - accuracy: 0.6580 - val_loss: 0.9665 - val_accuracy: 0.6634\n",
      "Epoch 156/200\n",
      "1407/1407 [==============================] - 10s 7ms/step - loss: 0.9695 - accuracy: 0.6580 - val_loss: 0.9579 - val_accuracy: 0.6704\n",
      "Epoch 157/200\n",
      "1407/1407 [==============================] - 10s 7ms/step - loss: 0.9716 - accuracy: 0.6600 - val_loss: 0.9797 - val_accuracy: 0.6628\n",
      "Epoch 158/200\n",
      "1407/1407 [==============================] - 10s 7ms/step - loss: 0.9754 - accuracy: 0.6597 - val_loss: 0.9747 - val_accuracy: 0.6674\n",
      "Epoch 159/200\n",
      "1407/1407 [==============================] - 11s 8ms/step - loss: 0.9738 - accuracy: 0.6589 - val_loss: 0.9507 - val_accuracy: 0.6776\n",
      "Epoch 160/200\n",
      "1407/1407 [==============================] - 12s 8ms/step - loss: 0.9663 - accuracy: 0.6590 - val_loss: 0.9721 - val_accuracy: 0.6608\n",
      "Epoch 161/200\n",
      "1407/1407 [==============================] - 11s 8ms/step - loss: 0.9684 - accuracy: 0.6603 - val_loss: 0.9654 - val_accuracy: 0.6610\n",
      "Epoch 162/200\n",
      "1407/1407 [==============================] - 10s 7ms/step - loss: 0.9708 - accuracy: 0.6591 - val_loss: 0.9492 - val_accuracy: 0.6778\n",
      "Epoch 163/200\n",
      "1407/1407 [==============================] - 10s 7ms/step - loss: 0.9693 - accuracy: 0.6593 - val_loss: 0.9746 - val_accuracy: 0.6662\n",
      "Epoch 164/200\n",
      "1407/1407 [==============================] - 10s 7ms/step - loss: 0.9726 - accuracy: 0.6599 - val_loss: 0.9517 - val_accuracy: 0.6796\n",
      "Epoch 165/200\n",
      "1407/1407 [==============================] - 11s 8ms/step - loss: 0.9724 - accuracy: 0.6598 - val_loss: 0.9647 - val_accuracy: 0.6682\n",
      "Epoch 166/200\n",
      "1407/1407 [==============================] - 12s 9ms/step - loss: 0.9736 - accuracy: 0.6590 - val_loss: 0.9741 - val_accuracy: 0.6610\n",
      "Epoch 167/200\n",
      "1407/1407 [==============================] - 11s 8ms/step - loss: 0.9655 - accuracy: 0.6608 - val_loss: 0.9638 - val_accuracy: 0.6644\n",
      "Epoch 168/200\n",
      "1407/1407 [==============================] - 10s 7ms/step - loss: 0.9706 - accuracy: 0.6590 - val_loss: 0.9853 - val_accuracy: 0.6614\n",
      "Epoch 169/200\n",
      "1407/1407 [==============================] - 12s 9ms/step - loss: 0.9665 - accuracy: 0.6599 - val_loss: 0.9450 - val_accuracy: 0.6776\n",
      "Epoch 170/200\n",
      "1407/1407 [==============================] - 12s 8ms/step - loss: 0.9661 - accuracy: 0.6611 - val_loss: 0.9594 - val_accuracy: 0.6742\n",
      "Epoch 171/200\n",
      "1407/1407 [==============================] - 12s 9ms/step - loss: 0.9670 - accuracy: 0.6592 - val_loss: 0.9574 - val_accuracy: 0.6678\n",
      "Epoch 172/200\n",
      "1407/1407 [==============================] - 11s 8ms/step - loss: 0.9622 - accuracy: 0.6618 - val_loss: 0.9469 - val_accuracy: 0.6672\n",
      "Epoch 173/200\n",
      "1407/1407 [==============================] - 11s 8ms/step - loss: 0.9722 - accuracy: 0.6636 - val_loss: 0.9627 - val_accuracy: 0.6728\n",
      "Epoch 174/200\n",
      "1407/1407 [==============================] - 11s 8ms/step - loss: 0.9668 - accuracy: 0.6623 - val_loss: 0.9612 - val_accuracy: 0.6716\n",
      "Epoch 175/200\n",
      "1407/1407 [==============================] - 15s 10ms/step - loss: 0.9700 - accuracy: 0.6592 - val_loss: 0.9738 - val_accuracy: 0.6668\n",
      "Epoch 176/200\n",
      "1407/1407 [==============================] - 16s 11ms/step - loss: 0.9598 - accuracy: 0.6638 - val_loss: 0.9501 - val_accuracy: 0.6658\n",
      "Epoch 177/200\n",
      "1407/1407 [==============================] - 11s 8ms/step - loss: 0.9669 - accuracy: 0.6596 - val_loss: 0.9422 - val_accuracy: 0.6826\n",
      "Epoch 178/200\n",
      "1407/1407 [==============================] - 16s 11ms/step - loss: 0.9589 - accuracy: 0.6626 - val_loss: 0.9388 - val_accuracy: 0.6772\n",
      "Epoch 179/200\n",
      "1407/1407 [==============================] - 19s 13ms/step - loss: 0.9623 - accuracy: 0.6654 - val_loss: 0.9510 - val_accuracy: 0.6778\n",
      "Epoch 180/200\n",
      "1407/1407 [==============================] - 15s 11ms/step - loss: 0.9675 - accuracy: 0.6590 - val_loss: 0.9681 - val_accuracy: 0.6642\n",
      "Epoch 181/200\n",
      "1407/1407 [==============================] - 15s 11ms/step - loss: 0.9704 - accuracy: 0.6594 - val_loss: 0.9464 - val_accuracy: 0.6744\n",
      "Epoch 182/200\n",
      "1407/1407 [==============================] - 12s 8ms/step - loss: 0.9689 - accuracy: 0.6581 - val_loss: 0.9477 - val_accuracy: 0.6792\n",
      "Epoch 183/200\n",
      "1407/1407 [==============================] - 13s 9ms/step - loss: 0.9625 - accuracy: 0.6620 - val_loss: 0.9502 - val_accuracy: 0.6766\n",
      "Epoch 184/200\n",
      "1407/1407 [==============================] - 11s 8ms/step - loss: 0.9623 - accuracy: 0.6642 - val_loss: 0.9531 - val_accuracy: 0.6750\n",
      "Epoch 185/200\n",
      "1407/1407 [==============================] - 11s 8ms/step - loss: 0.9679 - accuracy: 0.6614 - val_loss: 0.9631 - val_accuracy: 0.6712\n",
      "Epoch 186/200\n",
      "1407/1407 [==============================] - 10s 7ms/step - loss: 0.9691 - accuracy: 0.6613 - val_loss: 0.9497 - val_accuracy: 0.6700\n",
      "Epoch 187/200\n",
      "1407/1407 [==============================] - 10s 7ms/step - loss: 0.9586 - accuracy: 0.6630 - val_loss: 0.9685 - val_accuracy: 0.6658\n",
      "Epoch 188/200\n",
      "1407/1407 [==============================] - 12s 8ms/step - loss: 0.9626 - accuracy: 0.6610 - val_loss: 0.9527 - val_accuracy: 0.6730\n",
      "Epoch 189/200\n",
      "1407/1407 [==============================] - 11s 8ms/step - loss: 0.9615 - accuracy: 0.6621 - val_loss: 0.9454 - val_accuracy: 0.6744\n",
      "Epoch 190/200\n",
      "1407/1407 [==============================] - 15s 11ms/step - loss: 0.9618 - accuracy: 0.6641 - val_loss: 0.9456 - val_accuracy: 0.6790\n",
      "Epoch 191/200\n",
      "1407/1407 [==============================] - 12s 8ms/step - loss: 0.9662 - accuracy: 0.6609 - val_loss: 0.9513 - val_accuracy: 0.6712\n",
      "Epoch 192/200\n",
      "1407/1407 [==============================] - 11s 8ms/step - loss: 0.9580 - accuracy: 0.6633 - val_loss: 0.9556 - val_accuracy: 0.6680\n",
      "Epoch 193/200\n",
      "1407/1407 [==============================] - 11s 8ms/step - loss: 0.9631 - accuracy: 0.6614 - val_loss: 0.9558 - val_accuracy: 0.6760\n",
      "Epoch 194/200\n",
      "1407/1407 [==============================] - 12s 8ms/step - loss: 0.9614 - accuracy: 0.6614 - val_loss: 0.9459 - val_accuracy: 0.6700\n",
      "Epoch 195/200\n",
      "1407/1407 [==============================] - 11s 7ms/step - loss: 0.9679 - accuracy: 0.6597 - val_loss: 0.9637 - val_accuracy: 0.6702\n",
      "Epoch 196/200\n",
      "1407/1407 [==============================] - 12s 8ms/step - loss: 0.9619 - accuracy: 0.6610 - val_loss: 0.9554 - val_accuracy: 0.6770\n",
      "Epoch 197/200\n",
      "1407/1407 [==============================] - 11s 7ms/step - loss: 0.9678 - accuracy: 0.6624 - val_loss: 0.9686 - val_accuracy: 0.6722\n",
      "Epoch 198/200\n",
      "1407/1407 [==============================] - 11s 8ms/step - loss: 0.9657 - accuracy: 0.6628 - val_loss: 0.9559 - val_accuracy: 0.6704\n",
      "Epoch 199/200\n",
      "1407/1407 [==============================] - 12s 8ms/step - loss: 0.9553 - accuracy: 0.6634 - val_loss: 0.9416 - val_accuracy: 0.6832\n",
      "Epoch 200/200\n",
      "1407/1407 [==============================] - 12s 8ms/step - loss: 0.9636 - accuracy: 0.6619 - val_loss: 0.9466 - val_accuracy: 0.6780\n",
      "313/313 [==============================] - 1s 3ms/step - loss: 518.6017 - accuracy: 0.1691\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[518.6016845703125, 0.16910000145435333]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "batch_size = 32 \n",
    "num_epochs = 200 \n",
    "kernel_size = 2 # мы будем использовать ядра 3x3 повсюду\n",
    "pool_size = 2 # мы будем использовать объединение 2х2 повсюду\n",
    "conv_depth_1 = 32 # первоначально у нас будет 32 ядра на слой преобразования\n",
    "conv_depth_2 = 64 # переключение на 64 после первого уровня объединения\n",
    "drop_prob_1 = 0.25 # выбывает после объединения с вероятностью 0,25\n",
    "drop_prob_2 = 0.5 # выпадают в плотном слое с вероятностью 0,5\n",
    "hidden_size = 512 # в плотном слое будет 512 нейронов\n",
    "\n",
    "(X_train, y_train), (X_test, y_test) = cifar10.load_data() # извлечение данных CIFAR-10\n",
    "num_train, depth, height, width = X_train.shape # в CIFAR-10 содержится 50000 обучающих примеров\n",
    "num_test = X_test.shape[0] # в CIFAR-10 содержится 10000 тестовых примеров\n",
    "num_classes = np.unique(y_train).shape[0] # существует 10 классов изображений\n",
    "X_train = X_train.astype('float32')\n",
    "X_test = X_test.astype('float32')\n",
    "X_train /= np.max(X_train) # Нормализуйте данные до диапазона [0, 1]\n",
    "X_test /= np.max(X_train) # Нормализуйте данные до диапазона [0, 1]\n",
    "\n",
    "Y_train = np_utils.to_categorical(y_train, num_classes) # кодирование тренировачных данных\n",
    "Y_test = np_utils.to_categorical(y_test, num_classes) # кодирование тестировочных данных\n",
    "\n",
    "\n",
    "inp = Input(shape=(depth, height, width)) # N.B. глубина занимает первое место в Керасе\n",
    "# Conv [32] -> Conv [32] -> Pool (with dropout on the pooling layer)\n",
    "conv_1 = Convolution2D(conv_depth_1, kernel_size, kernel_size,\n",
    "padding='same', activation='relu')(inp) #устарело\n",
    "conv_2 = Convolution2D(conv_depth_1, kernel_size, kernel_size,\n",
    "padding='same', activation='relu')(conv_1)\n",
    "pool_1 = MaxPooling2D(pool_size=(pool_size, pool_size))(conv_2)\n",
    "drop_1 = Dropout(drop_prob_1)(pool_1)\n",
    "# Conv [64] -> Conv [64] -> Pool (with dropout on the pooling layer)\n",
    "conv_3 = Convolution2D(conv_depth_2, kernel_size, kernel_size,\n",
    "padding='same', activation='relu')(drop_1)\n",
    "conv_4 = Convolution2D(conv_depth_2, kernel_size, kernel_size,\n",
    "padding='same', activation='relu')(conv_3)\n",
    "pool_2 = MaxPooling2D(pool_size=(pool_size, pool_size),padding='same')(conv_4) # padding='same' входное изображение должно иметь нулевое заполнение, чтобы вывод в свертке не отличался по размеру от ввода. \n",
    "drop_2 = Dropout(drop_prob_1)(pool_2)\n",
    "#Теперь выровняйте до 1D, примените Плотный -> ReLU (с выпадением) -> softmax\n",
    "flat = Flatten()(drop_2)\n",
    "hidden = Dense(hidden_size, activation='relu')(flat)\n",
    "\n",
    "drop_3 = Dropout(drop_prob_2)(hidden)\n",
    "out = Dense(num_classes, activation='softmax')(drop_3)\n",
    "model = Model(inputs=inp, outputs=out) # Чтобы определить модель, просто укажите ее входные и выходные слои\n",
    "model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy']) \n",
    "model.fit(X_train, Y_train, batch_size=batch_size, epochs=num_epochs, verbose=1, validation_split=0.1) # \n",
    "model.evaluate(X_test, Y_test, verbose=1) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "68f452c0",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/200\n",
      "1407/1407 [==============================] - 10s 7ms/step - loss: 1.9883 - accuracy: 0.2312 - val_loss: 1.8137 - val_accuracy: 0.3108\n",
      "Epoch 2/200\n",
      "1407/1407 [==============================] - 7s 5ms/step - loss: 1.7936 - accuracy: 0.3249 - val_loss: 1.6782 - val_accuracy: 0.3890\n",
      "Epoch 3/200\n",
      "1407/1407 [==============================] - 7s 5ms/step - loss: 1.7052 - accuracy: 0.3647 - val_loss: 1.5901 - val_accuracy: 0.4246\n",
      "Epoch 4/200\n",
      "1407/1407 [==============================] - 10s 7ms/step - loss: 1.6577 - accuracy: 0.3882 - val_loss: 1.5584 - val_accuracy: 0.4266\n",
      "Epoch 5/200\n",
      "1407/1407 [==============================] - 9s 7ms/step - loss: 1.6189 - accuracy: 0.4005 - val_loss: 1.5131 - val_accuracy: 0.4446\n",
      "Epoch 6/200\n",
      "1407/1407 [==============================] - 10s 7ms/step - loss: 1.5897 - accuracy: 0.4157 - val_loss: 1.5003 - val_accuracy: 0.4382\n",
      "Epoch 7/200\n",
      "1407/1407 [==============================] - 10s 7ms/step - loss: 1.5664 - accuracy: 0.4255 - val_loss: 1.4465 - val_accuracy: 0.4606\n",
      "Epoch 8/200\n",
      "1407/1407 [==============================] - 9s 6ms/step - loss: 1.5485 - accuracy: 0.4307 - val_loss: 1.4373 - val_accuracy: 0.4768\n",
      "Epoch 9/200\n",
      "1407/1407 [==============================] - 8s 6ms/step - loss: 1.5270 - accuracy: 0.4425 - val_loss: 1.4337 - val_accuracy: 0.4724\n",
      "Epoch 10/200\n",
      "1407/1407 [==============================] - 9s 7ms/step - loss: 1.5096 - accuracy: 0.4483 - val_loss: 1.4255 - val_accuracy: 0.4798\n",
      "Epoch 11/200\n",
      "1407/1407 [==============================] - 9s 7ms/step - loss: 1.4950 - accuracy: 0.4538 - val_loss: 1.4017 - val_accuracy: 0.4998\n",
      "Epoch 12/200\n",
      "1407/1407 [==============================] - 12s 9ms/step - loss: 1.4869 - accuracy: 0.4574 - val_loss: 1.4290 - val_accuracy: 0.4840\n",
      "Epoch 13/200\n",
      "1407/1407 [==============================] - 11s 8ms/step - loss: 1.4756 - accuracy: 0.4594 - val_loss: 1.3966 - val_accuracy: 0.4978\n",
      "Epoch 14/200\n",
      "1407/1407 [==============================] - 9s 6ms/step - loss: 1.4633 - accuracy: 0.4688 - val_loss: 1.3864 - val_accuracy: 0.5006\n",
      "Epoch 15/200\n",
      "1407/1407 [==============================] - 11s 8ms/step - loss: 1.4536 - accuracy: 0.4719 - val_loss: 1.3889 - val_accuracy: 0.4994\n",
      "Epoch 16/200\n",
      "1407/1407 [==============================] - 9s 6ms/step - loss: 1.4434 - accuracy: 0.4729 - val_loss: 1.3946 - val_accuracy: 0.4944\n",
      "Epoch 17/200\n",
      "1407/1407 [==============================] - 9s 6ms/step - loss: 1.4352 - accuracy: 0.4804 - val_loss: 1.4024 - val_accuracy: 0.4960\n",
      "Epoch 18/200\n",
      "1407/1407 [==============================] - 9s 6ms/step - loss: 1.4304 - accuracy: 0.4802 - val_loss: 1.3412 - val_accuracy: 0.5146\n",
      "Epoch 19/200\n",
      "1407/1407 [==============================] - 8s 6ms/step - loss: 1.4239 - accuracy: 0.4833 - val_loss: 1.3812 - val_accuracy: 0.4990\n",
      "Epoch 20/200\n",
      "1407/1407 [==============================] - 7s 5ms/step - loss: 1.4129 - accuracy: 0.4869 - val_loss: 1.3558 - val_accuracy: 0.5142\n",
      "Epoch 21/200\n",
      "1407/1407 [==============================] - 8s 6ms/step - loss: 1.4130 - accuracy: 0.4900 - val_loss: 1.3420 - val_accuracy: 0.5196\n",
      "Epoch 22/200\n",
      "1407/1407 [==============================] - 10s 7ms/step - loss: 1.4024 - accuracy: 0.4932 - val_loss: 1.3427 - val_accuracy: 0.5202\n",
      "Epoch 23/200\n",
      "1407/1407 [==============================] - 12s 8ms/step - loss: 1.3998 - accuracy: 0.4921 - val_loss: 1.3458 - val_accuracy: 0.5178\n",
      "Epoch 24/200\n",
      "1407/1407 [==============================] - 10s 7ms/step - loss: 1.3983 - accuracy: 0.4945 - val_loss: 1.3653 - val_accuracy: 0.5128\n",
      "Epoch 25/200\n",
      "1407/1407 [==============================] - 10s 7ms/step - loss: 1.3918 - accuracy: 0.4973 - val_loss: 1.3366 - val_accuracy: 0.5156\n",
      "Epoch 26/200\n",
      "1407/1407 [==============================] - 9s 6ms/step - loss: 1.3874 - accuracy: 0.4986 - val_loss: 1.3575 - val_accuracy: 0.5078\n",
      "Epoch 27/200\n",
      "1407/1407 [==============================] - 9s 7ms/step - loss: 1.3861 - accuracy: 0.4975 - val_loss: 1.3589 - val_accuracy: 0.5138\n",
      "Epoch 28/200\n",
      "1407/1407 [==============================] - 9s 7ms/step - loss: 1.3843 - accuracy: 0.5010 - val_loss: 1.3415 - val_accuracy: 0.5240\n",
      "Epoch 29/200\n",
      "1407/1407 [==============================] - 9s 6ms/step - loss: 1.3768 - accuracy: 0.5035 - val_loss: 1.3578 - val_accuracy: 0.5098\n",
      "Epoch 30/200\n",
      "1407/1407 [==============================] - 9s 6ms/step - loss: 1.3745 - accuracy: 0.5035 - val_loss: 1.4087 - val_accuracy: 0.5034\n",
      "Epoch 31/200\n",
      "1407/1407 [==============================] - 8s 6ms/step - loss: 1.3650 - accuracy: 0.5029 - val_loss: 1.3490 - val_accuracy: 0.5182\n",
      "Epoch 32/200\n",
      "1407/1407 [==============================] - 9s 6ms/step - loss: 1.3650 - accuracy: 0.5071 - val_loss: 1.3807 - val_accuracy: 0.5116\n",
      "Epoch 33/200\n",
      "1407/1407 [==============================] - 19s 14ms/step - loss: 1.3630 - accuracy: 0.5090 - val_loss: 1.3647 - val_accuracy: 0.5104\n",
      "Epoch 34/200\n",
      "1407/1407 [==============================] - 7s 5ms/step - loss: 1.3626 - accuracy: 0.5076 - val_loss: 1.3528 - val_accuracy: 0.5166\n",
      "Epoch 35/200\n",
      "1407/1407 [==============================] - 7s 5ms/step - loss: 1.3624 - accuracy: 0.5084 - val_loss: 1.3671 - val_accuracy: 0.5144\n",
      "Epoch 36/200\n",
      "1407/1407 [==============================] - 7s 5ms/step - loss: 1.3536 - accuracy: 0.5119 - val_loss: 1.3436 - val_accuracy: 0.5262\n",
      "Epoch 37/200\n",
      "1407/1407 [==============================] - 7s 5ms/step - loss: 1.3513 - accuracy: 0.5136 - val_loss: 1.3424 - val_accuracy: 0.5172\n",
      "Epoch 38/200\n",
      "1407/1407 [==============================] - 8s 6ms/step - loss: 1.3510 - accuracy: 0.5122 - val_loss: 1.3454 - val_accuracy: 0.5210\n",
      "Epoch 39/200\n",
      "1407/1407 [==============================] - 10s 7ms/step - loss: 1.3479 - accuracy: 0.5134 - val_loss: 1.3504 - val_accuracy: 0.5194\n",
      "Epoch 40/200\n",
      "1407/1407 [==============================] - 14s 10ms/step - loss: 1.3454 - accuracy: 0.5135 - val_loss: 1.3487 - val_accuracy: 0.5202\n",
      "Epoch 41/200\n",
      "1407/1407 [==============================] - 10s 7ms/step - loss: 1.3413 - accuracy: 0.5147 - val_loss: 1.3396 - val_accuracy: 0.5256\n",
      "Epoch 42/200\n",
      "1407/1407 [==============================] - 9s 6ms/step - loss: 1.3344 - accuracy: 0.5183 - val_loss: 1.3425 - val_accuracy: 0.5204\n",
      "Epoch 43/200\n",
      "1407/1407 [==============================] - 9s 6ms/step - loss: 1.3417 - accuracy: 0.5184 - val_loss: 1.3447 - val_accuracy: 0.5214\n",
      "Epoch 44/200\n",
      "1407/1407 [==============================] - 9s 6ms/step - loss: 1.3360 - accuracy: 0.5167 - val_loss: 1.3690 - val_accuracy: 0.5208\n",
      "Epoch 45/200\n",
      "1407/1407 [==============================] - 8s 6ms/step - loss: 1.3339 - accuracy: 0.5180 - val_loss: 1.3604 - val_accuracy: 0.5136\n",
      "Epoch 46/200\n",
      "1407/1407 [==============================] - 9s 6ms/step - loss: 1.3306 - accuracy: 0.5188 - val_loss: 1.3376 - val_accuracy: 0.5266\n",
      "Epoch 47/200\n",
      "1407/1407 [==============================] - 9s 6ms/step - loss: 1.3229 - accuracy: 0.5226 - val_loss: 1.3357 - val_accuracy: 0.5170\n",
      "Epoch 48/200\n",
      "1407/1407 [==============================] - 8s 6ms/step - loss: 1.3302 - accuracy: 0.5222 - val_loss: 1.3407 - val_accuracy: 0.5204\n",
      "Epoch 49/200\n",
      "1407/1407 [==============================] - 9s 6ms/step - loss: 1.3293 - accuracy: 0.5193 - val_loss: 1.3412 - val_accuracy: 0.5126\n",
      "Epoch 50/200\n",
      "1407/1407 [==============================] - 9s 6ms/step - loss: 1.3267 - accuracy: 0.5223 - val_loss: 1.3407 - val_accuracy: 0.5164\n",
      "Epoch 51/200\n",
      "1407/1407 [==============================] - 9s 7ms/step - loss: 1.3281 - accuracy: 0.5211 - val_loss: 1.3357 - val_accuracy: 0.5224\n",
      "Epoch 52/200\n",
      "1407/1407 [==============================] - 9s 6ms/step - loss: 1.3198 - accuracy: 0.5246 - val_loss: 1.3375 - val_accuracy: 0.5232\n",
      "Epoch 53/200\n",
      "1407/1407 [==============================] - 9s 6ms/step - loss: 1.3223 - accuracy: 0.5222 - val_loss: 1.3610 - val_accuracy: 0.5136\n",
      "Epoch 54/200\n",
      "1407/1407 [==============================] - 8s 5ms/step - loss: 1.3183 - accuracy: 0.5269 - val_loss: 1.3385 - val_accuracy: 0.5270\n",
      "Epoch 55/200\n",
      "1407/1407 [==============================] - 9s 7ms/step - loss: 1.3136 - accuracy: 0.5269 - val_loss: 1.3273 - val_accuracy: 0.5308\n",
      "Epoch 56/200\n",
      "1407/1407 [==============================] - 8s 6ms/step - loss: 1.3097 - accuracy: 0.5306 - val_loss: 1.3371 - val_accuracy: 0.5286\n",
      "Epoch 57/200\n",
      "1407/1407 [==============================] - 7s 5ms/step - loss: 1.3150 - accuracy: 0.5278 - val_loss: 1.3264 - val_accuracy: 0.5306\n",
      "Epoch 58/200\n",
      "1407/1407 [==============================] - 9s 7ms/step - loss: 1.3119 - accuracy: 0.5287 - val_loss: 1.3186 - val_accuracy: 0.5312\n",
      "Epoch 59/200\n",
      "1407/1407 [==============================] - 8s 6ms/step - loss: 1.3103 - accuracy: 0.5268 - val_loss: 1.3314 - val_accuracy: 0.5358\n",
      "Epoch 60/200\n",
      "1407/1407 [==============================] - 8s 6ms/step - loss: 1.3071 - accuracy: 0.5318 - val_loss: 1.3494 - val_accuracy: 0.5158\n",
      "Epoch 61/200\n",
      "1407/1407 [==============================] - 8s 5ms/step - loss: 1.3074 - accuracy: 0.5316 - val_loss: 1.3433 - val_accuracy: 0.5260\n",
      "Epoch 62/200\n",
      "1407/1407 [==============================] - 9s 6ms/step - loss: 1.3075 - accuracy: 0.5293 - val_loss: 1.3554 - val_accuracy: 0.5194\n",
      "Epoch 63/200\n",
      "1407/1407 [==============================] - 9s 6ms/step - loss: 1.3052 - accuracy: 0.5315 - val_loss: 1.3196 - val_accuracy: 0.5394\n",
      "Epoch 64/200\n",
      "1407/1407 [==============================] - 9s 6ms/step - loss: 1.3001 - accuracy: 0.5335 - val_loss: 1.3563 - val_accuracy: 0.5180\n",
      "Epoch 65/200\n",
      "1407/1407 [==============================] - 11s 8ms/step - loss: 1.3014 - accuracy: 0.5304 - val_loss: 1.3460 - val_accuracy: 0.5302\n",
      "Epoch 66/200\n",
      "1407/1407 [==============================] - 9s 7ms/step - loss: 1.2973 - accuracy: 0.5332 - val_loss: 1.3373 - val_accuracy: 0.5224\n",
      "Epoch 67/200\n",
      "1407/1407 [==============================] - 9s 7ms/step - loss: 1.2954 - accuracy: 0.5341 - val_loss: 1.3483 - val_accuracy: 0.5190\n",
      "Epoch 68/200\n",
      "1407/1407 [==============================] - 8s 6ms/step - loss: 1.2992 - accuracy: 0.5317 - val_loss: 1.3804 - val_accuracy: 0.5106\n",
      "Epoch 69/200\n",
      "1407/1407 [==============================] - 8s 6ms/step - loss: 1.3020 - accuracy: 0.5293 - val_loss: 1.3631 - val_accuracy: 0.5198\n",
      "Epoch 70/200\n",
      "1407/1407 [==============================] - 8s 6ms/step - loss: 1.2921 - accuracy: 0.5388 - val_loss: 1.3310 - val_accuracy: 0.5324\n",
      "Epoch 71/200\n",
      "1407/1407 [==============================] - 8s 5ms/step - loss: 1.2920 - accuracy: 0.5371 - val_loss: 1.3400 - val_accuracy: 0.5254\n",
      "Epoch 72/200\n",
      "1407/1407 [==============================] - 7s 5ms/step - loss: 1.2888 - accuracy: 0.5383 - val_loss: 1.3290 - val_accuracy: 0.5296\n",
      "Epoch 73/200\n",
      "1407/1407 [==============================] - 10s 7ms/step - loss: 1.2879 - accuracy: 0.5361 - val_loss: 1.3379 - val_accuracy: 0.5170\n",
      "Epoch 74/200\n",
      "1407/1407 [==============================] - 9s 7ms/step - loss: 1.2860 - accuracy: 0.5377 - val_loss: 1.3208 - val_accuracy: 0.5302\n",
      "Epoch 75/200\n",
      "1407/1407 [==============================] - 9s 6ms/step - loss: 1.2823 - accuracy: 0.5414 - val_loss: 1.3342 - val_accuracy: 0.5324\n",
      "Epoch 76/200\n",
      "1407/1407 [==============================] - 7s 5ms/step - loss: 1.2853 - accuracy: 0.5416 - val_loss: 1.3287 - val_accuracy: 0.5346\n",
      "Epoch 77/200\n",
      "1407/1407 [==============================] - 7s 5ms/step - loss: 1.2852 - accuracy: 0.5392 - val_loss: 1.3361 - val_accuracy: 0.5238\n",
      "Epoch 78/200\n",
      "1407/1407 [==============================] - 8s 5ms/step - loss: 1.2791 - accuracy: 0.5388 - val_loss: 1.3341 - val_accuracy: 0.5260\n",
      "Epoch 79/200\n",
      "1407/1407 [==============================] - 8s 6ms/step - loss: 1.2886 - accuracy: 0.5424 - val_loss: 1.3234 - val_accuracy: 0.5336\n",
      "Epoch 80/200\n",
      "1407/1407 [==============================] - 6s 5ms/step - loss: 1.2854 - accuracy: 0.5400 - val_loss: 1.3263 - val_accuracy: 0.5224\n",
      "Epoch 81/200\n",
      "1407/1407 [==============================] - 6s 5ms/step - loss: 1.2821 - accuracy: 0.5396 - val_loss: 1.3663 - val_accuracy: 0.5258\n",
      "Epoch 82/200\n",
      "1407/1407 [==============================] - 8s 5ms/step - loss: 1.2809 - accuracy: 0.5402 - val_loss: 1.3361 - val_accuracy: 0.5388\n",
      "Epoch 83/200\n",
      "1407/1407 [==============================] - 6s 4ms/step - loss: 1.2815 - accuracy: 0.5396 - val_loss: 1.3326 - val_accuracy: 0.5290\n",
      "Epoch 84/200\n",
      "1407/1407 [==============================] - 6s 4ms/step - loss: 1.2697 - accuracy: 0.5422 - val_loss: 1.3275 - val_accuracy: 0.5318\n",
      "Epoch 85/200\n",
      "1407/1407 [==============================] - 6s 4ms/step - loss: 1.2766 - accuracy: 0.5439 - val_loss: 1.3533 - val_accuracy: 0.5270\n",
      "Epoch 86/200\n",
      "1407/1407 [==============================] - 6s 4ms/step - loss: 1.2689 - accuracy: 0.5462 - val_loss: 1.3284 - val_accuracy: 0.5306\n",
      "Epoch 87/200\n",
      "1407/1407 [==============================] - 6s 4ms/step - loss: 1.2776 - accuracy: 0.5417 - val_loss: 1.3223 - val_accuracy: 0.5340\n",
      "Epoch 88/200\n",
      "1407/1407 [==============================] - 6s 4ms/step - loss: 1.2731 - accuracy: 0.5441 - val_loss: 1.3378 - val_accuracy: 0.5248\n",
      "Epoch 89/200\n",
      "1407/1407 [==============================] - 6s 4ms/step - loss: 1.2704 - accuracy: 0.5468 - val_loss: 1.3417 - val_accuracy: 0.5202\n",
      "Epoch 90/200\n",
      "1407/1407 [==============================] - 6s 4ms/step - loss: 1.2722 - accuracy: 0.5451 - val_loss: 1.3399 - val_accuracy: 0.5220\n",
      "Epoch 91/200\n",
      "1407/1407 [==============================] - 6s 4ms/step - loss: 1.2673 - accuracy: 0.5459 - val_loss: 1.3359 - val_accuracy: 0.5246\n",
      "Epoch 92/200\n",
      "1407/1407 [==============================] - 6s 4ms/step - loss: 1.2680 - accuracy: 0.5435 - val_loss: 1.3521 - val_accuracy: 0.5232\n",
      "Epoch 93/200\n",
      "1407/1407 [==============================] - 6s 4ms/step - loss: 1.2630 - accuracy: 0.5468 - val_loss: 1.3375 - val_accuracy: 0.5242\n",
      "Epoch 94/200\n",
      "1407/1407 [==============================] - 6s 4ms/step - loss: 1.2664 - accuracy: 0.5451 - val_loss: 1.3276 - val_accuracy: 0.5234\n",
      "Epoch 95/200\n",
      "1407/1407 [==============================] - 6s 4ms/step - loss: 1.2663 - accuracy: 0.5456 - val_loss: 1.3388 - val_accuracy: 0.5234\n",
      "Epoch 96/200\n",
      "1407/1407 [==============================] - 7s 5ms/step - loss: 1.2615 - accuracy: 0.5491 - val_loss: 1.3380 - val_accuracy: 0.5248\n",
      "Epoch 97/200\n",
      "1407/1407 [==============================] - 9s 6ms/step - loss: 1.2553 - accuracy: 0.5490 - val_loss: 1.3315 - val_accuracy: 0.5302\n",
      "Epoch 98/200\n",
      "1407/1407 [==============================] - 7s 5ms/step - loss: 1.2605 - accuracy: 0.5476 - val_loss: 1.3268 - val_accuracy: 0.5304\n",
      "Epoch 99/200\n",
      "1407/1407 [==============================] - 7s 5ms/step - loss: 1.2664 - accuracy: 0.5480 - val_loss: 1.3338 - val_accuracy: 0.5230\n",
      "Epoch 100/200\n",
      "1407/1407 [==============================] - 6s 4ms/step - loss: 1.2623 - accuracy: 0.5504 - val_loss: 1.3638 - val_accuracy: 0.5182\n",
      "Epoch 101/200\n",
      "1407/1407 [==============================] - 6s 4ms/step - loss: 1.2665 - accuracy: 0.5480 - val_loss: 1.3363 - val_accuracy: 0.5312\n",
      "Epoch 102/200\n",
      "1407/1407 [==============================] - 8s 6ms/step - loss: 1.2615 - accuracy: 0.5482 - val_loss: 1.3286 - val_accuracy: 0.5318\n",
      "Epoch 103/200\n",
      "1407/1407 [==============================] - 11s 8ms/step - loss: 1.2617 - accuracy: 0.5490 - val_loss: 1.3762 - val_accuracy: 0.5156\n",
      "Epoch 104/200\n",
      "1407/1407 [==============================] - 9s 6ms/step - loss: 1.2624 - accuracy: 0.5490 - val_loss: 1.3632 - val_accuracy: 0.5186\n",
      "Epoch 105/200\n",
      "1407/1407 [==============================] - 8s 6ms/step - loss: 1.2538 - accuracy: 0.5500 - val_loss: 1.3237 - val_accuracy: 0.5244\n",
      "Epoch 106/200\n",
      "1407/1407 [==============================] - 8s 5ms/step - loss: 1.2535 - accuracy: 0.5512 - val_loss: 1.3536 - val_accuracy: 0.5182\n",
      "Epoch 107/200\n",
      "1407/1407 [==============================] - 8s 6ms/step - loss: 1.2579 - accuracy: 0.5494 - val_loss: 1.3372 - val_accuracy: 0.5250\n",
      "Epoch 108/200\n",
      "1407/1407 [==============================] - 8s 6ms/step - loss: 1.2569 - accuracy: 0.5508 - val_loss: 1.3228 - val_accuracy: 0.5206\n",
      "Epoch 109/200\n",
      "1407/1407 [==============================] - 7s 5ms/step - loss: 1.2535 - accuracy: 0.5508 - val_loss: 1.3561 - val_accuracy: 0.5194\n",
      "Epoch 110/200\n",
      "1407/1407 [==============================] - 7s 5ms/step - loss: 1.2565 - accuracy: 0.5500 - val_loss: 1.3340 - val_accuracy: 0.5226\n",
      "Epoch 111/200\n",
      "1407/1407 [==============================] - 8s 6ms/step - loss: 1.2591 - accuracy: 0.5486 - val_loss: 1.3322 - val_accuracy: 0.5172\n",
      "Epoch 112/200\n",
      "1407/1407 [==============================] - 9s 6ms/step - loss: 1.2515 - accuracy: 0.5504 - val_loss: 1.3243 - val_accuracy: 0.5178\n",
      "Epoch 113/200\n",
      "1407/1407 [==============================] - 8s 6ms/step - loss: 1.2511 - accuracy: 0.5544 - val_loss: 1.3570 - val_accuracy: 0.5246\n",
      "Epoch 114/200\n",
      "1407/1407 [==============================] - 7s 5ms/step - loss: 1.2517 - accuracy: 0.5512 - val_loss: 1.3379 - val_accuracy: 0.5132\n",
      "Epoch 115/200\n",
      "1407/1407 [==============================] - 7s 5ms/step - loss: 1.2534 - accuracy: 0.5514 - val_loss: 1.3305 - val_accuracy: 0.5286\n",
      "Epoch 116/200\n",
      "1407/1407 [==============================] - 8s 5ms/step - loss: 1.2482 - accuracy: 0.5528 - val_loss: 1.3700 - val_accuracy: 0.5178\n",
      "Epoch 117/200\n",
      "1407/1407 [==============================] - 8s 6ms/step - loss: 1.2503 - accuracy: 0.5527 - val_loss: 1.3417 - val_accuracy: 0.5318\n",
      "Epoch 118/200\n",
      "1407/1407 [==============================] - 9s 6ms/step - loss: 1.2540 - accuracy: 0.5522 - val_loss: 1.3534 - val_accuracy: 0.5202\n",
      "Epoch 119/200\n",
      "1407/1407 [==============================] - 9s 6ms/step - loss: 1.2441 - accuracy: 0.5559 - val_loss: 1.3357 - val_accuracy: 0.5182\n",
      "Epoch 120/200\n",
      "1407/1407 [==============================] - 7s 5ms/step - loss: 1.2496 - accuracy: 0.5555 - val_loss: 1.3293 - val_accuracy: 0.5244\n",
      "Epoch 121/200\n",
      "1407/1407 [==============================] - 7s 5ms/step - loss: 1.2451 - accuracy: 0.5558 - val_loss: 1.3361 - val_accuracy: 0.5194\n",
      "Epoch 122/200\n",
      "1407/1407 [==============================] - 7s 5ms/step - loss: 1.2436 - accuracy: 0.5560 - val_loss: 1.3237 - val_accuracy: 0.5314\n",
      "Epoch 123/200\n",
      "1407/1407 [==============================] - 7s 5ms/step - loss: 1.2479 - accuracy: 0.5542 - val_loss: 1.3386 - val_accuracy: 0.5262\n",
      "Epoch 124/200\n",
      "1407/1407 [==============================] - 7s 5ms/step - loss: 1.2500 - accuracy: 0.5537 - val_loss: 1.3377 - val_accuracy: 0.5256\n",
      "Epoch 125/200\n",
      "1407/1407 [==============================] - 7s 5ms/step - loss: 1.2449 - accuracy: 0.5555 - val_loss: 1.3467 - val_accuracy: 0.5216\n",
      "Epoch 126/200\n",
      "1407/1407 [==============================] - 7s 5ms/step - loss: 1.2395 - accuracy: 0.5582 - val_loss: 1.3220 - val_accuracy: 0.5302\n",
      "Epoch 127/200\n",
      "1407/1407 [==============================] - 7s 5ms/step - loss: 1.2447 - accuracy: 0.5533 - val_loss: 1.3294 - val_accuracy: 0.5242\n",
      "Epoch 128/200\n",
      "1407/1407 [==============================] - 7s 5ms/step - loss: 1.2464 - accuracy: 0.5564 - val_loss: 1.3336 - val_accuracy: 0.5252\n",
      "Epoch 129/200\n",
      "1407/1407 [==============================] - 8s 6ms/step - loss: 1.2354 - accuracy: 0.5590 - val_loss: 1.3322 - val_accuracy: 0.5102\n",
      "Epoch 130/200\n",
      "1407/1407 [==============================] - 7s 5ms/step - loss: 1.2451 - accuracy: 0.5565 - val_loss: 1.3451 - val_accuracy: 0.5230\n",
      "Epoch 131/200\n",
      "1407/1407 [==============================] - 9s 6ms/step - loss: 1.2388 - accuracy: 0.5576 - val_loss: 1.3345 - val_accuracy: 0.5214\n",
      "Epoch 132/200\n",
      "1407/1407 [==============================] - 9s 6ms/step - loss: 1.2378 - accuracy: 0.5563 - val_loss: 1.3421 - val_accuracy: 0.5180\n",
      "Epoch 133/200\n",
      "1407/1407 [==============================] - 7s 5ms/step - loss: 1.2344 - accuracy: 0.5588 - val_loss: 1.3156 - val_accuracy: 0.5318\n",
      "Epoch 134/200\n",
      "1407/1407 [==============================] - 8s 6ms/step - loss: 1.2409 - accuracy: 0.5561 - val_loss: 1.3317 - val_accuracy: 0.5244\n",
      "Epoch 135/200\n",
      "1407/1407 [==============================] - 8s 6ms/step - loss: 1.2382 - accuracy: 0.5544 - val_loss: 1.3332 - val_accuracy: 0.5266\n",
      "Epoch 136/200\n",
      "1407/1407 [==============================] - 8s 6ms/step - loss: 1.2435 - accuracy: 0.5569 - val_loss: 1.3466 - val_accuracy: 0.5178\n",
      "Epoch 137/200\n",
      "1407/1407 [==============================] - 8s 6ms/step - loss: 1.2399 - accuracy: 0.5561 - val_loss: 1.3312 - val_accuracy: 0.5296\n",
      "Epoch 138/200\n",
      "1407/1407 [==============================] - 8s 6ms/step - loss: 1.2441 - accuracy: 0.5561 - val_loss: 1.3374 - val_accuracy: 0.5260\n",
      "Epoch 139/200\n",
      "1407/1407 [==============================] - 8s 6ms/step - loss: 1.2348 - accuracy: 0.5588 - val_loss: 1.3454 - val_accuracy: 0.5240\n",
      "Epoch 140/200\n",
      "1407/1407 [==============================] - 8s 5ms/step - loss: 1.2375 - accuracy: 0.5565 - val_loss: 1.3540 - val_accuracy: 0.5184\n",
      "Epoch 141/200\n",
      "1407/1407 [==============================] - 8s 6ms/step - loss: 1.2413 - accuracy: 0.5566 - val_loss: 1.3265 - val_accuracy: 0.5282\n",
      "Epoch 142/200\n",
      "1407/1407 [==============================] - 8s 6ms/step - loss: 1.2334 - accuracy: 0.5613 - val_loss: 1.3375 - val_accuracy: 0.5264\n",
      "Epoch 143/200\n",
      "1407/1407 [==============================] - 11s 8ms/step - loss: 1.2324 - accuracy: 0.5605 - val_loss: 1.3342 - val_accuracy: 0.5188\n",
      "Epoch 144/200\n",
      "1407/1407 [==============================] - 10s 7ms/step - loss: 1.2317 - accuracy: 0.5613 - val_loss: 1.3493 - val_accuracy: 0.5148\n",
      "Epoch 145/200\n",
      "1407/1407 [==============================] - 10s 7ms/step - loss: 1.2413 - accuracy: 0.5545 - val_loss: 1.3292 - val_accuracy: 0.5222\n",
      "Epoch 146/200\n",
      "1407/1407 [==============================] - 7s 5ms/step - loss: 1.2384 - accuracy: 0.5564 - val_loss: 1.3229 - val_accuracy: 0.5194\n",
      "Epoch 147/200\n",
      "1407/1407 [==============================] - 8s 6ms/step - loss: 1.2346 - accuracy: 0.5592 - val_loss: 1.3390 - val_accuracy: 0.5132\n",
      "Epoch 148/200\n",
      "1407/1407 [==============================] - 8s 5ms/step - loss: 1.2348 - accuracy: 0.5607 - val_loss: 1.3370 - val_accuracy: 0.5252\n",
      "Epoch 149/200\n",
      "1407/1407 [==============================] - 7s 5ms/step - loss: 1.2405 - accuracy: 0.5570 - val_loss: 1.3339 - val_accuracy: 0.5222\n",
      "Epoch 150/200\n",
      "1407/1407 [==============================] - 7s 5ms/step - loss: 1.2374 - accuracy: 0.5572 - val_loss: 1.3752 - val_accuracy: 0.5198\n",
      "Epoch 151/200\n",
      "1407/1407 [==============================] - 7s 5ms/step - loss: 1.2316 - accuracy: 0.5600 - val_loss: 1.3304 - val_accuracy: 0.5288\n",
      "Epoch 152/200\n",
      "1407/1407 [==============================] - 8s 6ms/step - loss: 1.2292 - accuracy: 0.5612 - val_loss: 1.3379 - val_accuracy: 0.5214\n",
      "Epoch 153/200\n",
      "1407/1407 [==============================] - 8s 6ms/step - loss: 1.2293 - accuracy: 0.5642 - val_loss: 1.3155 - val_accuracy: 0.5294\n",
      "Epoch 154/200\n",
      "1407/1407 [==============================] - 7s 5ms/step - loss: 1.2310 - accuracy: 0.5629 - val_loss: 1.3506 - val_accuracy: 0.5214\n",
      "Epoch 155/200\n",
      "1407/1407 [==============================] - 8s 5ms/step - loss: 1.2340 - accuracy: 0.5584 - val_loss: 1.3418 - val_accuracy: 0.5240\n",
      "Epoch 156/200\n",
      "1407/1407 [==============================] - 8s 6ms/step - loss: 1.2292 - accuracy: 0.5619 - val_loss: 1.3421 - val_accuracy: 0.5180\n",
      "Epoch 157/200\n",
      "1407/1407 [==============================] - 7s 5ms/step - loss: 1.2325 - accuracy: 0.5589 - val_loss: 1.3256 - val_accuracy: 0.5214\n",
      "Epoch 158/200\n",
      "1407/1407 [==============================] - 7s 5ms/step - loss: 1.2309 - accuracy: 0.5615 - val_loss: 1.3454 - val_accuracy: 0.5200\n",
      "Epoch 159/200\n",
      "1407/1407 [==============================] - 7s 5ms/step - loss: 1.2305 - accuracy: 0.5626 - val_loss: 1.3526 - val_accuracy: 0.5138\n",
      "Epoch 160/200\n",
      "1407/1407 [==============================] - 8s 6ms/step - loss: 1.2269 - accuracy: 0.5609 - val_loss: 1.3322 - val_accuracy: 0.5250\n",
      "Epoch 161/200\n",
      "1407/1407 [==============================] - 8s 5ms/step - loss: 1.2288 - accuracy: 0.5610 - val_loss: 1.3567 - val_accuracy: 0.5128\n",
      "Epoch 162/200\n",
      "1407/1407 [==============================] - 12s 8ms/step - loss: 1.2320 - accuracy: 0.5623 - val_loss: 1.3355 - val_accuracy: 0.5186\n",
      "Epoch 163/200\n",
      "1407/1407 [==============================] - 12s 8ms/step - loss: 1.2300 - accuracy: 0.5584 - val_loss: 1.3360 - val_accuracy: 0.5188\n",
      "Epoch 164/200\n",
      "1407/1407 [==============================] - 11s 8ms/step - loss: 1.2300 - accuracy: 0.5624 - val_loss: 1.3227 - val_accuracy: 0.5298\n",
      "Epoch 165/200\n",
      "1407/1407 [==============================] - 11s 8ms/step - loss: 1.2232 - accuracy: 0.5641 - val_loss: 1.3340 - val_accuracy: 0.5224\n",
      "Epoch 166/200\n",
      "1407/1407 [==============================] - 9s 6ms/step - loss: 1.2245 - accuracy: 0.5639 - val_loss: 1.3258 - val_accuracy: 0.5258\n",
      "Epoch 167/200\n",
      "1407/1407 [==============================] - 9s 7ms/step - loss: 1.2268 - accuracy: 0.5622 - val_loss: 1.3349 - val_accuracy: 0.5272\n",
      "Epoch 168/200\n",
      "1407/1407 [==============================] - 9s 6ms/step - loss: 1.2218 - accuracy: 0.5651 - val_loss: 1.3334 - val_accuracy: 0.5224\n",
      "Epoch 169/200\n",
      "1407/1407 [==============================] - 8s 6ms/step - loss: 1.2261 - accuracy: 0.5650 - val_loss: 1.3582 - val_accuracy: 0.5138\n",
      "Epoch 170/200\n",
      "1407/1407 [==============================] - 8s 6ms/step - loss: 1.2247 - accuracy: 0.5636 - val_loss: 1.3337 - val_accuracy: 0.5168\n",
      "Epoch 171/200\n",
      "1407/1407 [==============================] - 8s 5ms/step - loss: 1.2261 - accuracy: 0.5623 - val_loss: 1.3350 - val_accuracy: 0.5192\n",
      "Epoch 172/200\n",
      "1407/1407 [==============================] - 8s 5ms/step - loss: 1.2255 - accuracy: 0.5626 - val_loss: 1.3334 - val_accuracy: 0.5164\n",
      "Epoch 173/200\n",
      "1407/1407 [==============================] - 8s 6ms/step - loss: 1.2222 - accuracy: 0.5642 - val_loss: 1.3312 - val_accuracy: 0.5314\n",
      "Epoch 174/200\n",
      "1407/1407 [==============================] - 7s 5ms/step - loss: 1.2288 - accuracy: 0.5627 - val_loss: 1.3379 - val_accuracy: 0.5188\n",
      "Epoch 175/200\n",
      "1407/1407 [==============================] - 9s 6ms/step - loss: 1.2242 - accuracy: 0.5637 - val_loss: 1.3443 - val_accuracy: 0.5244\n",
      "Epoch 176/200\n",
      "1407/1407 [==============================] - 8s 6ms/step - loss: 1.2189 - accuracy: 0.5658 - val_loss: 1.3346 - val_accuracy: 0.5200\n",
      "Epoch 177/200\n",
      "1407/1407 [==============================] - 7s 5ms/step - loss: 1.2138 - accuracy: 0.5671 - val_loss: 1.3325 - val_accuracy: 0.5218\n",
      "Epoch 178/200\n",
      "1407/1407 [==============================] - 7s 5ms/step - loss: 1.2230 - accuracy: 0.5643 - val_loss: 1.3373 - val_accuracy: 0.5148\n",
      "Epoch 179/200\n",
      "1407/1407 [==============================] - 8s 6ms/step - loss: 1.2260 - accuracy: 0.5635 - val_loss: 1.3389 - val_accuracy: 0.5260\n",
      "Epoch 180/200\n",
      "1407/1407 [==============================] - 8s 6ms/step - loss: 1.2185 - accuracy: 0.5658 - val_loss: 1.3266 - val_accuracy: 0.5226\n",
      "Epoch 181/200\n",
      "1407/1407 [==============================] - 7s 5ms/step - loss: 1.2182 - accuracy: 0.5630 - val_loss: 1.3280 - val_accuracy: 0.5184\n",
      "Epoch 182/200\n",
      "1407/1407 [==============================] - 9s 6ms/step - loss: 1.2127 - accuracy: 0.5696 - val_loss: 1.3373 - val_accuracy: 0.5226\n",
      "Epoch 183/200\n",
      "1407/1407 [==============================] - 8s 6ms/step - loss: 1.2227 - accuracy: 0.5637 - val_loss: 1.3739 - val_accuracy: 0.5118\n",
      "Epoch 184/200\n",
      "1407/1407 [==============================] - 9s 6ms/step - loss: 1.2175 - accuracy: 0.5673 - val_loss: 1.3173 - val_accuracy: 0.5264\n",
      "Epoch 185/200\n",
      "1407/1407 [==============================] - 9s 6ms/step - loss: 1.2172 - accuracy: 0.5672 - val_loss: 1.3324 - val_accuracy: 0.5162\n",
      "Epoch 186/200\n",
      "1407/1407 [==============================] - 9s 6ms/step - loss: 1.2176 - accuracy: 0.5661 - val_loss: 1.3390 - val_accuracy: 0.5266\n",
      "Epoch 187/200\n",
      "1407/1407 [==============================] - 10s 7ms/step - loss: 1.2115 - accuracy: 0.5658 - val_loss: 1.3342 - val_accuracy: 0.5256\n",
      "Epoch 188/200\n",
      "1407/1407 [==============================] - 8s 5ms/step - loss: 1.2149 - accuracy: 0.5643 - val_loss: 1.3273 - val_accuracy: 0.5290\n",
      "Epoch 189/200\n",
      "1407/1407 [==============================] - 8s 5ms/step - loss: 1.2209 - accuracy: 0.5665 - val_loss: 1.3342 - val_accuracy: 0.5242\n",
      "Epoch 190/200\n",
      "1407/1407 [==============================] - 8s 6ms/step - loss: 1.2213 - accuracy: 0.5669 - val_loss: 1.3545 - val_accuracy: 0.5176\n",
      "Epoch 191/200\n",
      "1407/1407 [==============================] - 9s 6ms/step - loss: 1.2170 - accuracy: 0.5671 - val_loss: 1.3314 - val_accuracy: 0.5310\n",
      "Epoch 192/200\n",
      "1407/1407 [==============================] - 8s 6ms/step - loss: 1.2173 - accuracy: 0.5623 - val_loss: 1.3433 - val_accuracy: 0.5238\n",
      "Epoch 193/200\n",
      "1407/1407 [==============================] - 8s 6ms/step - loss: 1.2216 - accuracy: 0.5632 - val_loss: 1.3314 - val_accuracy: 0.5282\n",
      "Epoch 194/200\n",
      "1407/1407 [==============================] - 8s 6ms/step - loss: 1.2140 - accuracy: 0.5666 - val_loss: 1.3294 - val_accuracy: 0.5280\n",
      "Epoch 195/200\n",
      "1407/1407 [==============================] - 9s 7ms/step - loss: 1.2097 - accuracy: 0.5688 - val_loss: 1.3447 - val_accuracy: 0.5184\n",
      "Epoch 196/200\n",
      "1407/1407 [==============================] - 8s 6ms/step - loss: 1.2143 - accuracy: 0.5657 - val_loss: 1.3366 - val_accuracy: 0.5210\n",
      "Epoch 197/200\n",
      "1407/1407 [==============================] - 9s 6ms/step - loss: 1.2211 - accuracy: 0.5650 - val_loss: 1.3420 - val_accuracy: 0.5252\n",
      "Epoch 198/200\n",
      "1407/1407 [==============================] - 7s 5ms/step - loss: 1.2160 - accuracy: 0.5676 - val_loss: 1.3237 - val_accuracy: 0.5236\n",
      "Epoch 199/200\n",
      "1407/1407 [==============================] - 7s 5ms/step - loss: 1.2094 - accuracy: 0.5702 - val_loss: 1.3454 - val_accuracy: 0.5272\n",
      "Epoch 200/200\n",
      "1407/1407 [==============================] - 7s 5ms/step - loss: 1.2068 - accuracy: 0.5708 - val_loss: 1.3446 - val_accuracy: 0.5216\n",
      "313/313 [==============================] - 1s 2ms/step - loss: 1565.2753 - accuracy: 0.2381\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[1565.2752685546875, 0.23810000717639923]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "batch_size = 32 \n",
    "num_epochs = 200 \n",
    "kernel_size = 5 # мы будем использовать ядра 3x3 повсюду\n",
    "pool_size = 2 # мы будем использовать объединение 2х2 повсюду\n",
    "conv_depth_1 = 32 # первоначально у нас будет 32 ядра на слой преобразования\n",
    "conv_depth_2 = 64 # переключение на 64 после первого уровня объединения\n",
    "drop_prob_1 = 0.25 # выбывает после объединения с вероятностью 0,25\n",
    "drop_prob_2 = 0.5 # выпадают в плотном слое с вероятностью 0,5\n",
    "hidden_size = 512 # в плотном слое будет 512 нейронов\n",
    "\n",
    "(X_train, y_train), (X_test, y_test) = cifar10.load_data() # извлечение данных CIFAR-10\n",
    "num_train, depth, height, width = X_train.shape # в CIFAR-10 содержится 50000 обучающих примеров\n",
    "num_test = X_test.shape[0] # в CIFAR-10 содержится 10000 тестовых примеров\n",
    "num_classes = np.unique(y_train).shape[0] # существует 10 классов изображений\n",
    "X_train = X_train.astype('float32')\n",
    "X_test = X_test.astype('float32')\n",
    "X_train /= np.max(X_train) # Нормализуйте данные до диапазона [0, 1]\n",
    "X_test /= np.max(X_train) # Нормализуйте данные до диапазона [0, 1]\n",
    "\n",
    "Y_train = np_utils.to_categorical(y_train, num_classes) # кодирование тренировачных данных\n",
    "Y_test = np_utils.to_categorical(y_test, num_classes) # кодирование тестировочных данных\n",
    "\n",
    "\n",
    "inp = Input(shape=(depth, height, width)) # N.B. глубина занимает первое место в Керасе\n",
    "# Conv [32] -> Conv [32] -> Pool (with dropout on the pooling layer)\n",
    "conv_1 = Convolution2D(conv_depth_1, kernel_size, kernel_size,\n",
    "padding='same', activation='relu')(inp) #устарело\n",
    "conv_2 = Convolution2D(conv_depth_1, kernel_size, kernel_size,\n",
    "padding='same', activation='relu')(conv_1)\n",
    "pool_1 = MaxPooling2D(pool_size=(pool_size, pool_size))(conv_2)\n",
    "drop_1 = Dropout(drop_prob_1)(pool_1)\n",
    "# Conv [64] -> Conv [64] -> Pool (with dropout on the pooling layer)\n",
    "conv_3 = Convolution2D(conv_depth_2, kernel_size, kernel_size,\n",
    "padding='same', activation='relu')(drop_1)\n",
    "conv_4 = Convolution2D(conv_depth_2, kernel_size, kernel_size,\n",
    "padding='same', activation='relu')(conv_3)\n",
    "pool_2 = MaxPooling2D(pool_size=(pool_size, pool_size),padding='same')(conv_4) # padding='same' входное изображение должно иметь нулевое заполнение, чтобы вывод в свертке не отличался по размеру от ввода. \n",
    "drop_2 = Dropout(drop_prob_1)(pool_2)\n",
    "#Теперь выровняйте до 1D, примените Плотный -> ReLU (с выпадением) -> softmax\n",
    "flat = Flatten()(drop_2)\n",
    "hidden = Dense(hidden_size, activation='relu')(flat)\n",
    "\n",
    "drop_3 = Dropout(drop_prob_2)(hidden)\n",
    "out = Dense(num_classes, activation='softmax')(drop_3)\n",
    "model = Model(inputs=inp, outputs=out) # Чтобы определить модель, просто укажите ее входные и выходные слои\n",
    "model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy']) \n",
    "model.fit(X_train, Y_train, batch_size=batch_size, epochs=num_epochs, verbose=1, validation_split=0.1) # \n",
    "model.evaluate(X_test, Y_test, verbose=1) "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
